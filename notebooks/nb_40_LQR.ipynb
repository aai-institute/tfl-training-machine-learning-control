{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "hide_input": false,
    "init_cell": true,
    "jupyter": {
     "source_hidden": true
    },
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "ActiveScene",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_ml_control\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "init_cell": true,
    "jupyter": {
     "source_hidden": true
    },
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "ActiveScene",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "ActiveScene",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "init_cell": true,
    "jupyter": {
     "source_hidden": true
    },
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "ActiveScene",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import casadi\n",
    "import do_mpc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from do_mpc.model import LinearModel\n",
    "from do_mpc.simulator import Simulator\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from training_ml_control.plots import (\n",
    "    plot_cart_results,\n",
    "    plot_inverted_pendulum_results,\n",
    ")\n",
    "from training_ml_control.environments import (\n",
    "    create_cart_environment,\n",
    "    create_inverted_pendulum_environment,\n",
    "    simulate_environment,\n",
    ")\n",
    "from training_ml_control.plots import (\n",
    "    animate_cart_simulation,\n",
    "    animate_inverted_pendulum_simulation,\n",
    ")\n",
    "from training_ml_control.control import (\n",
    "    build_lqr_controller,\n",
    ")\n",
    "from training_ml_control.models import (\n",
    "    build_cart_model,\n",
    "    build_inverted_pendulum_linear_model,\n",
    ")\n",
    "\n",
    "from training_ml_control.nb_utils import (\n",
    "    display_array,\n",
    "    show_video,\n",
    ")\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = [9, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "```{figure} ./_static/images/aai-institute-cover.png\n",
    ":width: 90%\n",
    ":align: center\n",
    "---\n",
    "name: aai-institute\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Quadratic Regulator\n",
    "\n",
    "While solving the optimal control problem (OCP) is very hard in general, there are a few very important special cases where the solutions are very accessible. Most of these involve variants on the case of linear dynamics and quadratic cost. The simplest case, called the linear quadratic regulator (LQR), is formulated as stabilizing a time-invariant linear system to the origin can be solved analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a discrete-time linear time-invariant system (LTI) described by:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = A \\mathbf{x}_t + B \\mathbf{u}_t\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x} \\in \\mathbb {R} ^{n}$ (that is, $\\mathbf{x}$ is an $n$-dimensional real-valued vector) is the state of the system and $\\mathbf{u} \\in \\mathbb {R} ^{m}$ is the control input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Horizon\n",
    "\n",
    "Given a quadratic cost function for the system in the finite-horizon case, defined as:\n",
    "|\n",
    "$$\n",
    "J(\\mathbf{x}_0, \\mathbf{u}, N) = \\mathbf{x}_N^{T} Q_N \\mathbf{x}_N + \\sum \\limits _{k = 0}^{N-1} \\mathbf{x}_k^{T}Q \\mathbf{x}_k + \\mathbf{u}_k^{T} R \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "With $Q_N = Q_N^T \\succeq 0$, $Q = Q^T \\succeq 0$, $R = R^T \\succeq 0$.\n",
    "\n",
    "It can be shown that the control law that minizes the cost is given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_k = K_k \\mathbf{x}_k\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_k = K_k (\\mathbf{x}_T - \\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "With: $K_k = -(R + B^T P_k B)^{-1} B^T P_k B$\n",
    "\n",
    "and $P_k$ is found by solving the discrete time dynamic Riccati equation:\n",
    "\n",
    "$$\n",
    "P_{k-1} = Q + A^{T}P_k A - (A^{T} P_k B)(R+B^{T}P_k B)^{-1}(B^{T}P_k A)\n",
    "$$\n",
    "\n",
    "With $P_N = Q_N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite Horizon\n",
    "\n",
    "Given a quadratic cost function for the system in the infinite-horizon case, defined as:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{x}_0, \\mathbf{u}) = \\sum \\limits _{k = 0}^{\\infty} \\mathbf{x}_k^{T}Q \\mathbf{x}_k + \\mathbf{u}_k^{T} R \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "With $Q = Q^T \\succeq 0$, $R = R^T \\succeq 0$.\n",
    "\n",
    "It can be shown that the control law that minizes the cost is given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_k = K \\mathbf{x}_k\n",
    "$$\n",
    "\n",
    "With: $K = -(R + B^T P B)^{-1} B^T P B$\n",
    "\n",
    "and $P$ is found by solving the discrete time algebraic Riccati equation (DARE):\n",
    "\n",
    "$$\n",
    "P = Q + A^{T}PA-(A^{T}PB)(R+B^{T}PB)^{-1}(B^{T}PA)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{figure} _static/images/30_lqr_block_diagram.svg\n",
    ":width: 60%\n",
    "LQR Block Diagram.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an LQR controller using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?? build_lqr_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we design Linear Quadratic Regulator for the Cart system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_env = create_cart_environment(goal_position=9)\n",
    "cart_model = build_cart_model(cart_env)\n",
    "cart_simulator = Simulator(cart_model)\n",
    "cart_simulator.set_param(t_step=cart_env.dt)\n",
    "cart_simulator.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create define the cost matrices and the setpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "Q = np.diag([100, 1])\n",
    "R = np.diag([10])\n",
    "setpoint = np.array([cart_env.goal_position, 0.0]).reshape(-1, 1)\n",
    "display_array(\"Q\", Q)\n",
    "display_array(\"R\", R)\n",
    "display_array(\"Setpoint\", setpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create an instance of `LQR` from the `do_mpc` package using the already defined `build_lqr_controller` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cart_lqr_controller = build_lqr_controller(\n",
    "    model=cart_model,\n",
    "    t_step=cart_env.dt,\n",
    "    n_horizon=None,\n",
    "    setpoint=setpoint,\n",
    "    Q=Q,\n",
    "    R=R,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SImulation\n",
    "\n",
    "Now, we simulate the closed-loop system for 50 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "cart_lqr_controller.reset_history()\n",
    "cart_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "cart_simulator.x0 = x0\n",
    "for _ in range(200):\n",
    "    u = cart_lqr_controller.make_step(x0)\n",
    "    x0 = cart_simulator.make_step(u)\n",
    "\n",
    "animate_cart_simulation(cart_lqr_controller.data, reference=cart_env.goal_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Finally, we evaluate the controller on the actual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LQRController:\n",
    "    def __init__(self, K: NDArray, setpoint: NDArray) -> None:\n",
    "        self.K = K\n",
    "        self.setpoint = setpoint.reshape(-1)\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        action = self.K @ (observation - self.setpoint)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "cart_controller = LQRController(K=cart_lqr_controller.K, setpoint=setpoint)\n",
    "results = simulate_environment(cart_env, max_steps=200, controller=cart_controller)\n",
    "show_video(results.frames, fps=1 / cart_env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "T = np.arange(len(results.observations)) * cart_env.dt\n",
    "plot_cart_results(\n",
    "    T=T,\n",
    "    observations=results.observations,\n",
    "    actions=results.actions,\n",
    "    reference=cart_env.goal_position,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted Pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise} Inverted Pendulum LQR Controller\n",
    ":label: lqr-controller\n",
    "Design an LQR controller to keep the inverted pendulum upright by following these steps:\n",
    "\n",
    "1. Define the $Q$ and $R$ matrices.\n",
    "1. Define setpoint $\\begin{bmatrix}\\theta_s \\\\ \\dot{\\theta}_s\\end{bmatrix} = \\begin{bmatrix}0.0 \\\\ 0.0 \\end{bmatrix}$.\n",
    "1. Create an lqr controller by calling the `build_lqr_controller` function and passing the appropriate arguments.\n",
    "1. Simulate the system using the simulator and the controller.\n",
    "1. Evaluate the controller on the environment.\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    ":::{solution} lqr-controller\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "::::{solution-start} lqr-controller\n",
    ":class: dropdown\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need the environment, linear model and simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_env = create_inverted_pendulum_environment(max_steps=200)\n",
    "inverted_pendulum_model = build_inverted_pendulum_linear_model(inverted_pendulum_env)\n",
    "inverted_pendulum_simulator = Simulator(inverted_pendulum_model)\n",
    "inverted_pendulum_simulator.set_param(t_step=inverted_pendulum_env.dt)\n",
    "inverted_pendulum_simulator.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to keep the inverted pendulum upright. For that we define the following objective matrices and setpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "Q = np.diag([100, 1])\n",
    "R = np.diag([10])\n",
    "setpoint = np.zeros((2, 1))\n",
    "display_array(\"Q\", Q)\n",
    "display_array(\"R\", R)\n",
    "display_array(\"Setpoint\", setpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lqr_controller = build_lqr_controller(\n",
    "    model=inverted_pendulum_model,\n",
    "    t_step=inverted_pendulum_env.dt,\n",
    "    n_horizon=None,\n",
    "    setpoint=setpoint,\n",
    "    Q=Q,\n",
    "    R=R,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lqr_controller.reset_history()\n",
    "inverted_pendulum_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "x0[0] = 0.01\n",
    "inverted_pendulum_simulator.x0 = x0\n",
    "\n",
    "for k in range(50):\n",
    "    u0 = inverted_pendulum_lqr_controller.make_step(x0)\n",
    "    x0 = inverted_pendulum_simulator.make_step(u0)\n",
    "\n",
    "animate_inverted_pendulum_simulation(inverted_pendulum_lqr_controller.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class LQRController:\n",
    "    def __init__(self, K: NDArray) -> None:\n",
    "        self.K = K\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return self.K @ observation[[2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "lqr_controller = LQRController(inverted_pendulum_lqr_controller.K)\n",
    "results = simulate_environment(\n",
    "    inverted_pendulum_env, max_steps=200, controller=lqr_controller\n",
    ")\n",
    "show_video(results.frames, fps=1 / inverted_pendulum_env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "T = np.arange(len(results.observations)) * inverted_pendulum_env.dt\n",
    "plot_inverted_pendulum_results(\n",
    "    T=T, observations=results.observations, actions=results.actions, reference=np.inf\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{solution-end}\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Iterative Linear Quadratic Regulator\n",
    "\n",
    "Iterative Linear Quadratic Regulator (iLQR) is an extension of LQR control to non-linear system with non-linear quadratic costs.\n",
    "\n",
    "The idea is to approximate the cost and dynamics as quadratic and affine, respectively, then exactly solve the resulting LQR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The basic flow of the algorithm is:\n",
    "\n",
    "1. Initialize with initial state $\\mathbf{x}_0$ and initial control sequence $\\mathbf{U} = \\{\\mathbf{u}_{0}, \\mathbf{u}_{1}, \\dots, \\mathbf{u}_{N-1}\\}$.\n",
    "2. Do a forward pass using the non-linear dynamics, i.e. simulate the system using $(\\mathbf{x}_0, \\mathbf{U})$ to get the trajectory through state space, $\\mathbf{X}$, that results from applying the control sequence $\\mathbf{X}$ starting in $\\mathbf{x}_0$.\n",
    "3. Do a backward pass, estimate the value function and dynamics for each $(\\mathbf{x}, \\mathbf{u})$ in the state-space and control signal trajectories.\n",
    "4. Calculate an updated control signal $\\hat{\\mathbf{U}}$ and evaluate cost of trajectory resulting from $(\\mathbf{x}_0, \\hat{\\mathbf{U}})$.\n",
    "   \n",
    "   1. If $|(\\textrm{cost}(x_0, \\hat{\\textbf{U}}) - \\textrm{cost}(x_0, \\textbf{U})| < \\textrm{threshold},$ then we've converged and exit.\n",
    "   2. If $\\textrm{cost}(x_0, \\hat{\\textbf{U}}) < \\textrm{cost}(x_0, \\textbf{U}),$ then set $\\textbf{U} = \\hat{\\textbf{U}},$ and change the update size to be more aggressive. Go back to step 2.\n",
    "   3. If $\\textrm{cost}(x_0, \\hat{\\textbf{U}}) \\geq \\textrm{cost}(x_0, \\textbf{U}),$ change the update size to be more modest. Go back to step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{note} Mathematical Derivation\n",
    ":class: dropdown\n",
    "\n",
    "Given a discrete-time non-linear system with state-space representation: \n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "$$\n",
    "\n",
    "we approximate it with a first-order Taylor-series expansion about nominal trajectories\n",
    "$\\mathbf{X} = \\{\\mathbf{x}_0, \\dots, \\mathbf{x}_N\\}, \\mathbf{U} = \\{ \\mathbf{u}_0, \\dots, \\mathbf{u}_N \\}$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\mathbf{x}_{t+1} + \\delta\\mathbf{x}_{t+1} &= f(\\mathbf{x}_t + \\delta \\mathbf{x}_t, \\mathbf{u}_t + \\delta \\mathbf{u}_t) \\\\ \n",
    "& \\approx f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{u}_t\\\\\n",
    "\\delta\\mathbf{x}_{t+1} &= A_t\\delta\\mathbf{x}_t + B_t\\delta\\mathbf{u}_t\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "with\n",
    "$A_t = A(\\mathbf{x}_t, \\mathbf{u}_t) = \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}$ and\n",
    "$B_t = B(\\mathbf{x}_t, \\mathbf{u}_t) = \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}$\n",
    "\n",
    "Given a general cost function that is not linear-quadratic, we use a second-order Taylor Series Expansion to linearize the dynamics into a form common for optimal control problems:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "J_N(\\mathbf{x}_0, \\mathbf{U}) &=\n",
    "l_f(\\mathbf{x}_N) + \\sum \\limits_{t=1}^{N-1} l(\\mathbf{x}_t, \\mathbf{u}_t)\\\\\n",
    "&\\approx \\frac{1}{2} \\mathbf{x}^T_N Q \\mathbf{x}_N + q_N^T \\mathbf{x}_N\n",
    "+ \\sum \\limits_{t=1}^{N-1}\n",
    "\\frac{1}{2} \\mathbf{x}^T_t Q_t \\mathbf{x}_t\n",
    "+ \\frac{1}{2} \\mathbf{u}^T_t R_t \\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\mathbf{x}^T_t H_t \\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\mathbf{u}^T_t H_t^T \\mathbf{x}_t\n",
    "+ q_t^T \\mathbf{x}_t +  + r_t^T \\mathbf{u}_t\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We define the following variables for convenience:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "l_x &:= \\frac{\\partial l}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = Q_t \\mathbf{x}_t + q_t\n",
    "\\\\\n",
    "l_u &:= \\frac{\\partial l}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = R_t \\mathbf{u}_t + r_t\n",
    "\\\\\n",
    "l_{xx} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t} = Q_t\n",
    "\\\\\n",
    "l_{uu} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{u}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t} = R_t\n",
    "\\\\\n",
    "l_{xu} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{x}\\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = H_t\n",
    "\\\\\n",
    "l_{ux} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{u}\\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = H_t^T\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We can apply Bellman's Principle of Optimality to define the optimal cost-to-go:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "V_N(\\mathbf{x}_N) &= g_f(\\mathbf{x}_N)\\\\\n",
    "V_{t}(\\mathbf{x}_t) &= \\displaystyle \\min_u {g(\\mathbf{x}_{t}, \\mathbf{u}_{t}) + V_{t+1}(f(\\mathbf{x}_{t}, \\mathbf{u}_{N-t}))}\\\\\n",
    "V_{t}(\\mathbf{x}_t) &= \\displaystyle \\min_u Q_{t}(\\mathbf{x}_{t}, \\mathbf{u}_{t})\n",
    "\\end{array}\\\\\n",
    "$$\n",
    "\n",
    "The $Q$-function is the discrete-time analogue of the Hamiltonian, sometimes known as the pseudo-Hamiltonian.\n",
    "\n",
    "We approximate the cost-to-go function as locally quadratic near the nominal trajectory gives us (we drop the time index in some of the equations for the sake of readability):\n",
    "\n",
    "$$\n",
    "\\delta V(\\mathbf{x}) = s^T \\delta\\mathbf{x} + \\frac{1}{2} \\delta\\mathbf{x}^T S \\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "with \n",
    "$s = \\frac{\\partial V}{\\partial \\mathbf{x}}|_{\\mathbf{x}},\n",
    "S = \\frac{\\partial^2 V}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}}$\n",
    "\n",
    "Similarily:\n",
    "\n",
    "$$\n",
    "\\delta Q(\\mathbf{x}, \\mathbf{u}) = \n",
    "\\frac{1}{2}\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}^T\n",
    "\\begin{bmatrix} Q_{xx} & Q_{xu} \\\\ Q_{ux} & Q_{uu} \\end{bmatrix}\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} Q_{x} \\\\ Q_{u} \\end{bmatrix}^T\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "Q_x &= l_x + s_{t+1} A_t \\\\\n",
    "Q_u &= l_u + s_{t+1} B_t \\\\\n",
    "Q_{xx} &= l_{xx} + A_t^T S_{t+1} A_t \\\\\n",
    "Q_{uu} &= l_{uu} + B_t^T S_{t+1} B_t \\\\\n",
    "Q_{ux} &= l_{ux} + B_t^T S_{t+1} A_t\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The optimal control modification $\\delta\\mathbf{u}^∗$ for some state perturbation $\\delta\\mathbf{x}$, is obtained by minimizing the quadratic model:\n",
    "\n",
    "$$\n",
    "\\delta\\mathbf{u}^∗(\\delta\\mathbf{x}) = \\displaystyle\\arg\\min_{\\delta\\mathbf{u}} Q(\\delta\\mathbf{x}, \\delta\\mathbf{u}) = k + K\\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "This is a locally-linear feedback policy with:\n",
    "\n",
    "$$\n",
    "k := -Q_{uu}^{-1}Q_u\\\\\n",
    "K := -Q_{uu}^{-1}Q_{ux}\n",
    "$$\n",
    "\n",
    "Plugging this back into the expansion of $Q$, a quadratic model of $V$ is obtained. After simplification it is:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\Delta V &= \\frac{1}{2} k^T Q_{uu} k + k^T Q_u\\\\\n",
    "s &= Q_x + K^T Q_{uu} k + K^T Q_u + Q_{ux}^T k\\\\\n",
    "S &= Q_{xx} + K^T Q_{uu} K + K^T Q_{ux} + Q_{ux}^T K\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Once these terms are computed, a forward pass computes a new trajectory:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\hat{x}_0 &= x_0\\\\\n",
    "\\hat{u}_t &= u_t + k_t + K_t(\\hat{x}_t - x_t)\\\\\n",
    "\\hat{x}_{t+1} &= f(\\hat{x}_t, \\hat{u}_t)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "scenes_data": {
   "active_scene": "Initialization",
   "init_scene": "Initialization",
   "scenes": [
    "Initialization"
   ]
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
