@incollection{bensoussan_machine_2022,
  title = {Machine Learning and Control Theory},
  booktitle = {Handbook of {{Numerical Analysis}}},
  author = {Bensoussan, Alain and Li, Yiqun and Nguyen, Dinh Phan Cao and Tran, Minh-Binh and Yam, Sheung Chi Phillip and Zhou, Xiang},
  date = {2022},
  volume = {23},
  pages = {531--558},
  publisher = {Elsevier},
  doi = {10.1016/bs.hna.2021.12.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1570865921000314},
  urldate = {2023-12-19},
  abstract = {We survey in this article the connections between Machine Learning and Control Theory. Control Theory provide useful concepts and tools for Machine Learning. Conversely Machine Learning can be used to solve large control problems. In the first part of the paper, we develop the connections between reinforcement learning and Markov Decision Processes, which are discrete time control problems. In the second part, we review the concept of supervised learning and the relation with static optimization. Deep learning which extends supervised learning, can be viewed as a control problem. In the third part, we present the links between stochastic gradient descent and mean field theory. Conversely, in the fourth and fifth parts, we review machine learning approaches to stochastic control problems,and focus on the deterministic case, to explain, more easily, the numerical algorithms.},
  isbn = {978-0-323-85059-9},
  langid = {english}
}

@book{bertsekas_lessons_2022,
  title = {Lessons from {{AlphaZero}} for {{Optimal}}, {{Model Predictive}}, and {{Adaptive Control}}},
  author = {Bertsekas, Dimitri P},
  date = {2022-08},
  abstract = {The purpose of this book is to propose and develop a new conceptual framework for approximate Dynamic Programming (DP) and Reinforcement Learning (RL). This framework centers around two algorithms, which are designed largely independently of each other and operate in synergy through the powerful mechanism of Newton's method. We call these the off-line training and the on-line play algorithms; the names are borrowed from some of the major successes of RL involving games. Primary examples are the recent (2017) AlphaZero program (which plays chess), and the similarly structured and earlier (1990s) TD-Gammon program (which plays backgammon). In these game contexts, the off-line training algorithm is the method used to teach the program how to evaluate positions and to generate good moves at any given position, while the on-line play algorithm is the method used to play in real time against human or computer opponents. Both AlphaZero and TD-Gammon were trained off-line extensively using neural networks and an approximate version of the fundamental DP algorithm of policy iteration. Yet the AlphaZero player that was obtained off-line is not used directly during on-line play (it is too inaccurate due to approximation errors that are inherent in off-line neural network training). Instead a separate on-line player is used to select moves, based on multistep lookahead minimization and a terminal position evaluator that was trained using experience with the off-line player. The on-line player performs a form of policy improvement, which is not degraded by neural network approximations. As a result, it greatly improves the performance of the off-line player. Similarly, TD-Gammon performs on-line a policy improvement step using one-step or two-step lookahead minimization, which is not degraded by neural network approximations. To this end it uses an off-line neural network-trained terminal position evaluator, and importantly it also extends its on-line lookahead by rollout (simulation with the one-step lookahead player that is based on the position evaluator). Significantly, the synergy between off-line training and on-line play also underlies Model Predictive Control (MPC), a major control system design methodology that has been extensively developed since the 1980s. This synergy can be understood in terms of abstract models of infinite horizon DP and simple geometrical constructions, and helps to explain the all-important stability issues within the MPC context. An additional benefit of policy improvement by approximation in value space, not observed in the context of games (which have stable rules and environment), is that it works well with changing problem parameters and on-line replanning, similar to indirect adaptive control. Here the Bellman equation is perturbed due to the parameter changes, but approximation in value space still operates as a Newton step. An essential requirement here is that a system model is estimated on-line through some identification method, and is used during the one-step or multistep lookahead minimization process. In this monograph we aim to provide insights (often based on visualization), which explain the beneficial effects of on-line decision making on top of off-line training. In the process, we will bring out the strong connections between the artificial intelligence view of RL, and the control theory views of MPC and adaptive control. Moreover, we will show that in addition to MPC and adaptive control, our conceptual framework can be effectively integrated with other important methodologies such as multiagent systems and decentralized control, discrete and Bayesian optimization, and heuristic algorithms for discrete optimization. One of our principal aims is to show, through the algorithmic ideas of Newton's method and the unifying principles of abstract DP, that the AlphaZero/TD-Gammon methodology of approximation in value space and rollout applies very broadly to deterministic and stochastic optimal control problems. Newton's method here is used for the solution of Bellman's equation, an operator equation that applies universally within DP with both discrete and continuous state and control spaces, as well as finite and infinite horizon.},
  isbn = {978-1-886529-17-5},
  langid = {english},
  pagetotal = {237}
}

@article{bevanda_koopman_2021,
  title = {Koopman Operator Dynamical Models: {{Learning}}, Analysis and Control},
  shorttitle = {Koopman Operator Dynamical Models},
  author = {Bevanda, Petar and Sosnowski, Stefan and Hirche, Sandra},
  date = {2021-01-01},
  journaltitle = {Annual Reviews in Control},
  shortjournal = {Annual Reviews in Control},
  volume = {52},
  pages = {197--212},
  issn = {1367-5788},
  doi = {10.1016/j.arcontrol.2021.09.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1367578821000729},
  urldate = {2023-12-01},
  abstract = {The Koopman operator allows for handling nonlinear systems through a globally linear representation. In general, the operator is infinite-dimensional – necessitating finite approximations – for which there is no overarching framework. Although there are principled ways of learning such finite approximations, they are in many instances overlooked in favor of, often ill-posed and unstructured methods. Also, Koopman operator theory has long-standing connections to known system-theoretic and dynamical system notions that are not universally recognized. Given the former and latter realities, this work aims to bridge the gap between various concepts regarding both theory and tractable realizations. Firstly, we review data-driven representations (both unstructured and structured) for Koopman operator dynamical models, categorizing various existing methodologies and highlighting their differences. Furthermore, we provide concise insight into the paradigm’s relation to system-theoretic notions and analyze the prospect of using the paradigm for modeling control systems. Additionally, we outline the current challenges and comment on future perspectives.}
}

@article{brunke_safe_2022,
  title = {Safe {{Learning}} in {{Robotics}}: {{From Learning-Based Control}} to {{Safe Reinforcement Learning}}},
  shorttitle = {Safe {{Learning}} in {{Robotics}}},
  author = {Brunke, Lukas and Greeff, Melissa and Hall, Adam W. and Yuan, Zhaocong and Zhou, Siqi and Panerati, Jacopo and Schoellig, Angela P.},
  date = {2022-05-03},
  journaltitle = {Annual Review of Control, Robotics, and Autonomous Systems},
  shortjournal = {Annu. Rev. Control Robot. Auton. Syst.},
  volume = {5},
  number = {1},
  pages = {411--444},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-042920-020211},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-control-042920-020211},
  urldate = {2023-10-16},
  abstract = {The last half decade has seen a steep rise in the number of contributions on safe learning methods for real-world robotic deployments from both the control and reinforcement learning communities. This article provides a concise but holistic review of the recent advances made in using machine learning to achieve safe decision-making under uncertainties, with a focus on unifying the language and frameworks used in control theory and reinforcement learning research. It includes learning-based control approaches that safely improve performance by learning the uncertain dynamics, reinforcement learning approaches that encourage safety or robustness, and methods that can formally certify the safety of a learned control policy. As data- and learning-based robot control methods continue to gain traction, researchers must understand when and how to best leverage them in real-world scenarios where safety is imperative, such as when operating in close proximityto humans. We highlight some of the open challenges that will drive the field of robot learning in the coming years, and emphasize the need for realistic physics-based benchmarks to facilitate fair comparisons between control and reinforcement learning approaches.},
  langid = {english}
}

@article{brunton_discovering_2016,
  title = {Discovering Governing Equations from Data by Sparse Identification of Nonlinear Dynamical Systems},
  author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
  date = {2016-04-12},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {113},
  number = {15},
  eprint = {27035946},
  eprinttype = {pmid},
  pages = {3932--3937},
  publisher = {National Academy of Sciences},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1517384113},
  url = {https://www.pnas.org/content/113/15/3932},
  urldate = {2021-03-28},
  abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.},
  langid = {english}
}

@article{brunton_modern_2022,
  title = {Modern {{Koopman Theory}} for {{Dynamical Systems}}},
  author = {Brunton, Steven L. and Budišić, Marko and Kaiser, Eurika and Kutz, J. Nathan},
  date = {2022-05-05},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  volume = {64},
  number = {2},
  pages = {229--340},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/21M1401243},
  url = {https://epubs.siam.org/doi/doi/10.1137/21M1401243},
  urldate = {2024-04-17},
  abstract = {We establish the convergence of a class of numerical algorithms, known as dynamic mode decomposition (DMD), for computation of the eigenvalues and eigenfunctions of the infinite-dimensional Koopman operator.  The algorithms act on data coming from observables on a state space, arranged in Hankel-type matrices. The proofs utilize the assumption that  the underlying dynamical system  is ergodic. This includes the classical measure-preserving systems, as well as systems whose attractors support a physical measure. Our approach relies on the observation that vector projections in DMD can be used to approximate the function projections by the virtue of Birkhoff's ergodic theorem. Using this fact, we show that applying DMD to Hankel data matrices in the limit of infinite-time observations yields the true Koopman eigenfunctions and eigenvalues. We also show that the singular value decomposition, which is the central part of most DMD algorithms,  converges to the proper orthogonal decomposition of observables. We use this result to obtain a representation of the dynamics of systems with continuous spectrum based on the lifting of the coordinates to the space of observables. The numerical application of these methods is demonstrated using well-known dynamical systems and examples from computational fluid dynamics.}
}

@online{brunton_sparse_2016,
  title = {Sparse {{Identification}} of {{Nonlinear Dynamics}} with {{Control}} ({{SINDYc}})},
  author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
  date = {2016-05-21},
  url = {https://arxiv.org/abs/1605.06682v1},
  urldate = {2024-05-14},
  abstract = {Identifying governing equations from data is a critical step in the modeling and control of complex dynamical systems. Here, we investigate the data-driven identification of nonlinear dynamical systems with inputs and forcing using regression methods, including sparse regression. Specifically, we generalize the sparse identification of nonlinear dynamics (SINDY) algorithm to include external inputs and feedback control. This method is demonstrated on examples including the Lotka-Volterra predator--prey model and the Lorenz system with forcing and control. We also connect the present algorithm with the dynamic mode decomposition (DMD) and Koopman operator theory to provide a broader context.},
  langid = {english},
  organization = {arXiv.org}
}

@article{cerf_combining_2023,
  title = {Combining Neural Networks and Control: Potentialities, Patterns and Perspectives},
  shorttitle = {Combining Neural Networks and Control},
  author = {Cerf, Sophie and Rutten, Éric},
  date = {2023-01-01},
  journaltitle = {IFAC-PapersOnLine},
  shortjournal = {IFAC-PapersOnLine},
  series = {22nd {{IFAC World Congress}}},
  volume = {56},
  number = {2},
  pages = {9036--9049},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2023.10.134},
  url = {https://www.sciencedirect.com/science/article/pii/S2405896323004809},
  urldate = {2023-12-19},
  abstract = {Machine learning tools are widely used for knowledge extraction, modeling, and decision tasks; a range of problems that Control Theory also tackles. Their relations have been largely explored by looking at stochastic control and Markov Decision Processes, due to the proximity of their formulations. However, novel links between machine learning and deterministic control are emerging; combining both approaches, e.g. by performing identification with learning, or controlling the training process. The recent flourishing literature is vast: there is a need to identify challenges, trends and opportunities on this interface. This survey contributes i) to the compared analysis of both fields. ii) Based on literature review, a categorization of combinations of learning and control is drawn. In the control framework, learning has been used for modeling, controllers tuning or adaptation, generating a controller or as a controller itself, for translating complex objectives, or checking controlled systems. Conversely, in the learning framework, control is used for tuning hyperparameters, selecting or generating training data, as the training or decision-making algorithm itself or to guarantee learning properties. iii) Finally, discussions on the literature open novel promising combinations to be explored, such as control of neural networks’ training process.},
  langid = {english}
}

@online{colbrook_multiverse_2023,
  title = {The {{Multiverse}} of {{Dynamic Mode Decomposition Algorithms}}},
  author = {Colbrook, Matthew J.},
  date = {2023-11-01},
  doi = {10.48550/arXiv.2312.00137},
  url = {https://ui.adsabs.harvard.edu/abs/2023arXiv231200137C},
  urldate = {2024-04-14},
  abstract = {Dynamic Mode Decomposition (DMD) is a popular data-driven analysis technique used to decompose complex, nonlinear systems into a set of modes, revealing underlying patterns and dynamics through spectral analysis. This review presents a comprehensive and pedagogical examination of DMD, emphasizing the role of Koopman operators in transforming complex nonlinear dynamics into a linear framework. A distinctive feature of this review is its focus on the relationship between DMD and the spectral properties of Koopman operators, with particular emphasis on the theory and practice of DMD algorithms for spectral computations. We explore the diverse "multiverse" of DMD methods, categorized into three main areas: linear regression-based methods, Galerkin approximations, and structure-preserving techniques. Each category is studied for its unique contributions and challenges, providing a detailed overview of significant algorithms and their applications as outlined in Table 1. We include a MATLAB package with examples and applications to enhance the practical understanding of these methods. This review serves as both a practical guide and a theoretical reference for various DMD methods, accessible to both experts and newcomers, and enabling readers to delve into their areas of interest in the expansive field of DMD.},
  organization = {arXiv e-prints},
  pubstate = {preprint},
  annotation = {ADS Bibcode: 2023arXiv231200137C}
}

@article{dogra_optimizing_2020,
  title = {Optimizing {{Neural Networks}} via {{Koopman Operator Theory}}},
  author = {Dogra, Akshunna S and Redman, William T},
  date = {2020},
  journaltitle = {Advances in Neural Information Processing Systems},
  shortjournal = {Adv. Neural Inf. Process. Syst.},
  volume = {33},
  pages = {2087--2097},
  abstract = {Koopman operator theory, a powerful framework for discovering the underlying dynamics of nonlinear dynamical systems, was recently shown to be intimately connected with neural network training. In this work, we take the first steps in making use of this connection. As Koopman operator theory is a linear theory, a successful implementation of it in evolving network weights and biases offers the promise of accelerated training, especially in the context of deep networks, where optimization is inherently a non-convex problem. We show that Koopman operator theoretic methods allow for accurate predictions of weights and biases of feedforward, fully connected deep networks over a non-trivial range of training time. During this window, we find that our approach is {$>$}10x faster than various gradient descent based methods (e.g. Adam, Adadelta, Adagrad), in line with our complexity analysis. We end by highlighting open questions in this exciting intersection between dynamical systems and neural network theory, and additional methods by which our results may be generalized.},
  langid = {english}
}

@online{fasel_sindy_2021,
  title = {{{SINDy}} with {{Control}}: {{A Tutorial}}},
  shorttitle = {{{SINDy}} with {{Control}}},
  author = {Fasel, Urban and Kaiser, Eurika and Kutz, J. Nathan and Brunton, Bingni W. and Brunton, Steven L.},
  date = {2021-08-30},
  url = {https://arxiv.org/abs/2108.13404v1},
  urldate = {2024-05-14},
  abstract = {Many dynamical systems of interest are nonlinear, with examples in turbulence, epidemiology, neuroscience, and finance, making them difficult to control using linear approaches. Model predictive control (MPC) is a powerful model-based optimization technique that enables the control of such nonlinear systems with constraints. However, modern systems often lack computationally tractable models, motivating the use of system identification techniques to learn accurate and efficient models for real-time control. In this tutorial article, we review emerging data-driven methods for model discovery and how they are used for nonlinear MPC. In particular, we focus on the sparse identification of nonlinear dynamics (SINDy) algorithm and show how it may be used with MPC on an infectious disease control example. We compare the performance against MPC based on a linear dynamic mode decomposition (DMD) model. Code is provided to run the tutorial examples and may be modified to extend this data-driven control framework to arbitrary nonlinear systems.},
  langid = {english},
  organization = {arXiv.org}
}

@book{goodwin_control_2000,
  title = {Control {{System Desig}}},
  author = {Goodwin, Graham C.},
  date = {2000},
  publisher = {CONTROL SYSTEM DESIG}
}

@online{goyal_generalized_2024,
  title = {Generalized {{Quadratic Embeddings}} for {{Nonlinear Dynamics}} Using {{Deep Learning}}},
  author = {Goyal, Pawan and Benner, Peter},
  date = {2024-01-04},
  eprint = {2211.00357},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2211.00357},
  urldate = {2024-03-07},
  abstract = {The engineering design process often relies on mathematical modeling that can describe the underlying dynamic behavior. In this work, we present a data-driven methodology for modeling the dynamics of nonlinear systems. To simplify this task, we aim to identify a coordinate transformation that allows us to represent the dynamics of nonlinear systems using a common, simple model structure. The advantage of a common simple model is that customized design tools developed for it can be applied to study a large variety of nonlinear systems. The simplest common model—one can think of — is linear, but linear systems often fall short in accurately capturing the complex dynamics of nonlinear systems. In this work, we propose using quadratic systems as the common structure, inspired by the lifting principle. According to this principle, smooth nonlinear systems can be expressed as quadratic systems in suitable coordinates without approximation errors. However, finding these coordinates solely from data is challenging. Here, we leverage deep learning to identify such lifted coordinates using only data, enabling a quadratic dynamical system to describe the system’s dynamics. Additionally, we discuss the asymptotic stability of these quadratic dynamical systems. We illustrate the approach using data collected from various numerical examples, demonstrating its superior performance with the existing well-known techniques.},
  langid = {english},
  pubstate = {preprint}
}

@online{goyal_guaranteed_2024,
  title = {Guaranteed {{Stable Quadratic Models}} and Their Applications in {{SINDy}} and {{Operator Inference}}},
  author = {Goyal, Pawan and Duff, Igor Pontes and Benner, Peter},
  date = {2024-01-07},
  eprint = {2308.13819},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2308.13819},
  urldate = {2024-03-07},
  abstract = {Scientific machine learning for inferring dynamical systems combines data-driven modeling, physics-based modeling, and empirical knowledge. It plays an essential role in engineering design and digital twinning. In this work, we primarily focus on an operator inference methodology that builds dynamical models, preferably in low-dimension, with a prior hypothesis on the model structure, often determined by known physics or given by experts. Then, for inference, we aim to learn the operators of a model by setting up an appropriate optimization problem.},
  langid = {english},
  pubstate = {preprint}
}

@incollection{grune_nonlinear_2017,
  title = {Nonlinear {{Model Predictive Control}}},
  booktitle = {Nonlinear {{Model Predictive Control}}: {{Theory}} and {{Algorithms}}},
  author = {Grüne, Lars and Pannek, Jürgen},
  editor = {Grüne, Lars and Pannek, Jürgen},
  date = {2017},
  series = {Communications and {{Control Engineering}}},
  pages = {45--69},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-46024-6_3},
  url = {https://doi.org/10.1007/978-3-319-46024-6_3},
  urldate = {2023-10-07},
  abstract = {In this chapter, we introduce the nonlinear model predictive control algorithm in a rigorous way. We start by defining a basic NMPC algorithm for constant reference and continue by formalizing state and control constraints. Viability (or weak forward invariance) of the set of state constraints is introduced and the consequences for the admissibility of the NMPC-feedback law are discussed. After having introduced NMPC in a special setting, we describe various extensions of the basic algorithm, considering time varying reference solutions, terminal constraints, and costs and additional weights. Finally, we investigate the optimal control problem corresponding to this generalized setting and prove several properties, most notably the dynamic programming principle.},
  isbn = {978-3-319-46024-6},
  langid = {english}
}

@inproceedings{gu_efficiently_2022,
  title = {Efficiently Modeling Long Sequences with Structured State Spaces},
  author = {Gu, Albert and Goel, Karan and Re, Christopher},
  date = {2022-03-04},
  eprint = {2111.00396},
  eprinttype = {arxiv},
  url = {https://openreview.net/forum?id=uYLFoz1vlAC},
  urldate = {2022-08-12},
  abstract = {A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of 10000 or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) \textbackslash ( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) \textbackslash ), and showed that for appropriate choices of the state matrix \textbackslash ( A \textbackslash ), this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning \textbackslash ( A \textbackslash ) with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91\textbackslash\% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation 60× faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  annotation = {blog:https://srush.github.io/annotated-s4/}
}

@inproceedings{gu_qlmor_2009,
  title = {{{QLMOR}}: A New Projection-Based Approach for Nonlinear Model Order Reduction},
  shorttitle = {{{QLMOR}}},
  booktitle = {Proceedings of the 2009 {{International Conference}} on {{Computer-Aided Design}}},
  author = {Gu, Chenjie},
  date = {2009-11-02},
  pages = {389--396},
  publisher = {ACM},
  location = {San Jose California},
  doi = {10.1145/1687399.1687474},
  url = {https://dl.acm.org/doi/10.1145/1687399.1687474},
  urldate = {2024-03-07},
  abstract = {We present a new projection-based nonlinear model order reduction method, named QLMOR (MOR via quadratic-linear systems). QLMOR employs two novel ideas: (1) we show that DAEs (differentialalgebraic equations) with many commonly-encountered nonlinear kernels can be re-written equivalently into a special format, QLDAEs (quadratic-linear differential algebraic equations, i.e., DAEs that are quadratic in their state variables and linear in their inputs); (2) we adapt the moment-matching reduction technique of NORM[1] to reduce these QLDAEs into QLDAEs of much smaller size.},
  eventtitle = {{{ICCAD}} '09: {{The International Conference}} on {{Computer-Aided Design}}},
  isbn = {978-1-60558-800-1},
  langid = {english}
}

@article{h.tu_dynamic_2014,
  title = {On Dynamic Mode Decomposition: {{Theory}} and Applications},
  shorttitle = {On Dynamic Mode Decomposition},
  author = {H. Tu, Jonathan and W. Rowley, Clarence and M. Luchtenburg, Dirk and L. Brunton, Steven and Nathan Kutz, J. and {,Dept. of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ 08544} and {,Dept. of Applied Mathematics, University of Washington, Seattle, WA 98195}},
  date = {2014},
  journaltitle = {Journal of Computational Dynamics},
  shortjournal = {J. Comput. Dyn.},
  volume = {1},
  number = {2},
  eprint = {1312.0041},
  eprinttype = {arxiv},
  pages = {391--421},
  issn = {2158-2505},
  doi = {10.3934/jcd.2014.1.391},
  url = {http://aimsciences.org//article/doi/10.3934/jcd.2014.1.391},
  urldate = {2024-04-17},
  abstract = {Originally introduced in the fluid mechanics community, dynamic mode decomposition (DMD) has emerged as a powerful tool for analyzing the dynamics of nonlinear systems. However, existing DMD theory deals primarily with sequential time series for which the measurement dimension is much larger than the number of measurements taken. We present a theoretical framework in which we define DMD as the eigendecomposition of an approximating linear operator. This generalizes DMD to a larger class of datasets, including nonsequential time series. We demonstrate the utility of this approach by presenting novel sampling strategies that increase computational efficiency and mitigate the effects of noise, respectively. We also introduce the concept of linear consistency, which helps explain the potential pitfalls of applying DMD to rank-deficient datasets, illustrating with examples. Such computations are not considered in the existing literature but can be understood using our more general framework. In addition, we show that our theory strengthens the connections between DMD and Koopman operator theory. It also establishes connections between DMD and other techniques, including the eigensystem realization algorithm (ERA), a system identification method, and linear inverse modeling (LIM), a method from climate science. We show that under certain conditions, DMD is equivalent to LIM.},
  langid = {english}
}

@article{hewing_learningbased_2020,
  title = {Learning-{{Based Model Predictive Control}}: {{Toward Safe Learning}} in {{Control}}},
  shorttitle = {Learning-{{Based Model Predictive Control}}},
  author = {Hewing, Lukas and Wabersich, Kim P. and Menner, Marcel and Zeilinger, Melanie N.},
  date = {2020-05-03},
  journaltitle = {Annual Review of Control, Robotics, and Autonomous Systems},
  shortjournal = {Annu. Rev. Control Robot. Auton. Syst.},
  volume = {3},
  number = {1},
  pages = {269--296},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-090419-075625},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-control-090419-075625},
  urldate = {2023-10-16},
  abstract = {Recent successes in the field of machine learning, as well as the availability of increased sensing and computational capabilities in modern control systems, have led to a growing interest in learning and data-driven control techniques. Model predictive control (MPC), as the prime methodology for constrained control, offers a significant opportunity to exploit the abundance of data in a reliable manner, particularly while taking safety constraints into account. This review aims at summarizing and categorizing previous research on learning-based MPC, i.e., the integration or combination of MPC with learning methods, for which we consider three main categories. Most of the research addresses learning for automatic improvement of the prediction model from recorded data. There is, however, also an increasing interest in techniques to infer the parameterization of the MPC controller, i.e., the cost and constraints, that lead to the best closed-loop performance. Finally, we discuss concepts that leverage MPC to augment learning-based controllers with constraint satisfaction properties.},
  langid = {english}
}

@article{korda_linear_2018,
  title = {Linear Predictors for Nonlinear Dynamical Systems: {{Koopman}} Operator Meets Model Predictive Control},
  shorttitle = {Linear Predictors for Nonlinear Dynamical Systems},
  author = {Korda, Milan and Mezić, Igor},
  date = {2018-07-01},
  journaltitle = {Automatica},
  shortjournal = {Automatica},
  volume = {93},
  pages = {149--160},
  issn = {0005-1098},
  doi = {10.1016/j.automatica.2018.03.046},
  url = {https://www.sciencedirect.com/science/article/pii/S000510981830133X},
  urldate = {2024-03-07},
  abstract = {This paper presents a class of linear predictors for nonlinear controlled dynamical systems. The basic idea is to lift (or embed) the nonlinear dynamics into a higher dimensional space where its evolution is approximately linear. In an uncontrolled setting, this procedure amounts to numerical approximations of the Koopman operator associated to the nonlinear dynamics. In this work, we extend the Koopman operator to controlled dynamical systems and apply the Extended Dynamic Mode Decomposition (EDMD) to compute a finite-dimensional approximation of the operator in such a way that this approximation has the form of a linear controlled dynamical system. In numerical examples, the linear predictors obtained in this way exhibit a performance superior to existing linear predictors such as those based on local linearization or the so called Carleman linearization. Importantly, the procedure to construct these linear predictors is completely data-driven and extremely simple – it boils down to a nonlinear transformation of the data (the lifting) and a linear least squares problem in the lifted space that can be readily solved for large data sets. These linear predictors can be readily used to design controllers for the nonlinear dynamical system using linear controller design methodologies. We focus in particular on model predictive control (MPC) and show that MPC controllers designed in this way enjoy computational complexity of the underlying optimization problem comparable to that of MPC for a linear dynamical system with the same number of control inputs and the same dimension of the state-space. Importantly, linear inequality constraints on the state and control inputs as well as nonlinear constraints on the state can be imposed in a linear fashion in the proposed MPC scheme. Similarly, cost functions nonlinear in the state variable can be handled in a linear fashion. We treat both the full-state measurement case and the input–output case, as well as systems with disturbances/noise. Numerical examples demonstrate the approach.1}
}

@article{lusch_deep_2018,
  title = {Deep Learning for Universal Linear Embeddings of Nonlinear Dynamics},
  author = {Lusch, Bethany and Kutz, J. Nathan and Brunton, Steven L.},
  date = {2018-11-23},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {9},
  number = {1},
  pages = {4950},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-07210-0},
  url = {https://www.nature.com/articles/s41467-018-07210-0},
  urldate = {2024-03-07},
  abstract = {Abstract             Identifying coordinate transformations that make strongly nonlinear dynamics approximately linear has the potential to enable nonlinear prediction, estimation, and control using linear theory. The Koopman operator is a leading data-driven embedding, and its eigenfunctions provide intrinsic coordinates that globally linearize the dynamics. However, identifying and representing these eigenfunctions has proven challenging. This work leverages deep learning to discover representations of Koopman eigenfunctions from data. Our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold. We identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. We also generalize Koopman representations to include a ubiquitous class of systems with continuous spectra. Our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding, while connecting our models to decades of asymptotics. Thus, we benefit from the power of deep learning, while retaining the physical interpretability of Koopman embeddings.},
  langid = {english}
}

@article{otto_koopman_2021,
  title = {Koopman {{Operators}} for {{Estimation}} and {{Control}} of {{Dynamical Systems}}},
  author = {Otto, Samuel E. and Rowley, Clarence W.},
  date = {2021-05-03},
  journaltitle = {Annual Review of Control, Robotics, and Autonomous Systems},
  shortjournal = {Annu. Rev. Control Robot. Auton. Syst.},
  volume = {4},
  number = {1},
  pages = {59--87},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-071020-010108},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-control-071020-010108},
  urldate = {2023-12-01},
  abstract = {A common way to represent a system’s dynamics is to specify how the state evolves in time. An alternative viewpoint is to specify how functions of the state evolve in time. This evolution of functions is governed by a linear operator called the Koopman operator, whose spectral properties reveal intrinsic features of a system. For instance, its eigenfunctions determine coordinates in which the dynamics evolve linearly. This review discusses the theoretical foundations of Koopman operator methods, as well as numerical methods developed over the past two decades to approximate the Koopman operator from data, for systems both with and without actuation. We pay special attention to ergodic systems, for which especially effective numerical methods are available. For nonlinear systems with an affine control input, the Koopman formalism leads naturally to systems that are bilinear in the state and the input, and this structure can be leveraged for the design of controllers and estimators.},
  langid = {english}
}

@article{pan_physicsinformed_2020,
  title = {Physics-{{Informed Probabilistic Learning}} of {{Linear Embeddings}} of {{Non-linear Dynamics With Guaranteed Stability}}},
  author = {Pan, Shaowu and Duraisamy, Karthik},
  date = {2020-01},
  journaltitle = {SIAM Journal on Applied Dynamical Systems},
  shortjournal = {SIAM J. Appl. Dyn. Syst.},
  volume = {19},
  number = {1},
  eprint = {1906.03663},
  eprinttype = {arxiv},
  eprintclass = {math, stat},
  pages = {480--509},
  issn = {1536-0040},
  doi = {10.1137/19M1267246},
  url = {http://arxiv.org/abs/1906.03663},
  urldate = {2024-03-07},
  abstract = {The Koopman operator has emerged as a powerful tool for the analysis of nonlinear dynamical systems as it provides coordinate transformations to globally linearize the dynamics. While recent deep learning approaches have been useful in extracting the Koopman operator from a data-driven perspective, several challenges remain. In this work, we formalize the problem of learning the continuous-time Koopman operator with deep neural networks in a measure-theoretic framework. Our approach induces two types of models: differential and recurrent form, the choice of which depends on the availability of the governing equations and data. We then enforce a structural parameterization that renders the realization of the Koopman operator provably stable. A new autoencoder architecture is constructed, such that only the residual of the dynamic mode decomposition is learned. Finally, we employ mean-field variational inference (MFVI) on the aforementioned framework in a hierarchical Bayesian setting to quantify uncertainties in the characterization and prediction of the dynamics of observables. The framework is evaluated on a simple polynomial system, the Duffing oscillator, and an unstable cylinder wake flow with noisy measurements.},
  langid = {english}
}

@article{proctor_dynamic_2016,
  title = {Dynamic {{Mode Decomposition}} with {{Control}}},
  author = {Proctor, Joshua L. and Brunton, Steven L. and Kutz, J. Nathan},
  date = {2016-01},
  journaltitle = {SIAM Journal on Applied Dynamical Systems},
  shortjournal = {SIAM J. Appl. Dyn. Syst.},
  volume = {15},
  number = {1},
  pages = {142--161},
  issn = {1536-0040},
  doi = {10.1137/15M1013857},
  url = {http://epubs.siam.org/doi/10.1137/15M1013857},
  urldate = {2024-04-19},
  abstract = {We develop a new method which extends dynamic mode decomposition (DMD) to incorporate the effect of control to extract low-order models from high-dimensional, complex systems. DMD finds spatial-temporal coherent modes, connects local-linear analysis to nonlinear operator theory, and provides an equation-free architecture which is compatible with compressive sensing. In actuated systems, DMD is incapable of producing an input-output model; moreover, the dynamics and the modes will be corrupted by external forcing. Our new method, dynamic mode decomposition with control (DMDc), capitalizes on all of the advantages of DMD and provides the additional innovation of being able to disambiguate between the underlying dynamics and the effects of actuation, resulting in accurate input-output models. The method is data-driven in that it does not require knowledge of the underlying governing equations—only snapshots in time of observables and actuation data from historical, experimental, or black-box simulations. We demonstrate the method on high-dimensional dynamical systems, including a model with relevance to the analysis of infectious disease data with mass vaccination (actuation).},
  langid = {english}
}

@article{proctor_generalizing_2018,
  title = {Generalizing {{Koopman Theory}} to {{Allow}} for {{Inputs}} and {{Control}}},
  author = {Proctor, Joshua L. and Brunton, Steven L. and Kutz, J. Nathan},
  date = {2018-01},
  journaltitle = {SIAM Journal on Applied Dynamical Systems},
  shortjournal = {SIAM J. Appl. Dyn. Syst.},
  volume = {17},
  number = {1},
  pages = {909--930},
  issn = {1536-0040},
  doi = {10.1137/16M1062296},
  url = {https://epubs.siam.org/doi/10.1137/16M1062296},
  urldate = {2024-03-07},
  abstract = {We develop a new generalization of Koopman operator theory that incorporates the effects of inputs and control. Koopman spectral analysis is a theoretical tool for the analysis of nonlinear dynamical systems. Moreover, Koopman is intimately connected to dynamic mode decomposition (DMD), a method that discovers coherent, spatio-temporal modes from data, connects local-linear analysis to nonlinear operator theory, and importantly creates an equation-free architecture for the study of complex systems. For actuated systems, standard Koopman analysis and DMD are incapable of producing input-output models; moreover, the dynamics and the modes will be corrupted by external forcing. Our new theoretical developments extend Koopman operator theory to allow for systems with nonlinear input-output characteristics. We show how this generalization is rigorously connected to a recent development called dynamic mode decomposition with control. We demonstrate this new theory on nonlinear dynamical systems, including a standard susceptible-infectious-recovered model with relevance to the analysis of infectious disease data with mass vaccination (actuation).},
  langid = {english}
}

@article{qian_lift_2020,
  title = {Lift \& {{Learn}}: {{Physics-informed}} Machine Learning for Large-Scale Nonlinear Dynamical Systems},
  shorttitle = {Lift \& {{Learn}}},
  author = {Qian, Elizabeth and Kramer, Boris and Peherstorfer, Benjamin and Willcox, Karen},
  date = {2020-05-01},
  journaltitle = {Physica D: Nonlinear Phenomena},
  shortjournal = {Physica D: Nonlinear Phenomena},
  volume = {406},
  pages = {132401},
  issn = {0167-2789},
  doi = {10.1016/j.physd.2020.132401},
  url = {https://www.sciencedirect.com/science/article/pii/S0167278919307651},
  urldate = {2024-03-07},
  abstract = {We present Lift \& Learn, a physics-informed method for learning low-dimensional models for large-scale dynamical systems. The method exploits knowledge of a system’s governing equations to identify a coordinate transformation in which the system dynamics have quadratic structure. This transformation is called a lifting map because it often adds auxiliary variables to the system state. The lifting map is applied to data obtained by evaluating a model for the original nonlinear system. This lifted data is projected onto its leading principal components, and low-dimensional linear and quadratic matrix operators are fit to the lifted reduced data using a least-squares operator inference procedure. Analysis of our method shows that the Lift \& Learn models are able to capture the system physics in the lifted coordinates at least as accurately as traditional intrusive model reduction approaches. This preservation of system physics makes the Lift \& Learn models robust to changes in inputs. Numerical experiments on the FitzHugh–Nagumo neuron activation model and the compressible Euler equations demonstrate the generalizability of our model.}
}

@article{rosolia_datadriven_2018,
  title = {Data-{{Driven Predictive Control}} for {{Autonomous Systems}}},
  author = {Rosolia, Ugo and Zhang, Xiaojing and Borrelli, Francesco},
  date = {2018-05-28},
  journaltitle = {Annual Review of Control, Robotics, and Autonomous Systems},
  shortjournal = {Annu. Rev. Control Robot. Auton. Syst.},
  volume = {1},
  number = {1},
  pages = {259--286},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-060117-105215},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-control-060117-105215},
  urldate = {2023-10-16},
  abstract = {In autonomous systems, the ability to make forecasts and cope with uncertain predictions is synonymous with intelligence. Model predictive control (MPC) is an established control methodology that systematically uses forecasts to compute real-time optimal control decisions. In MPC, at each time step an optimization problem is solved over a moving horizon. The objective is to find a control policy that minimizes a predicted performance index while satisfying operating constraints. Uncertainty in MPC is handled by optimizing over multiple uncertain forecasts. In this case, performance index and operating constraints take the form of functions defined over a probability space, and the resulting technique is called stochastic MPC. Our research over the past 10 years has focused on predictive control design methods that systematically handle uncertain forecasts in autonomous and semiautonomous systems. In the first part of this article, we present an overview of the approach we use, its main advantages, and its challenges. In the second part, we present our most recent results on data-driven predictive control. We show how to use data to efficiently formulate stochastic MPC problems and autonomously improve performance in repetitive tasks. The proposed framework is able to handle a large set of predicted scenarios in real time and learn from historical data.},
  langid = {english}
}

@article{savageau_recasting_1987,
  title = {Recasting Nonlinear Differential Equations as {{S-systems}}: A Canonical Nonlinear Form},
  shorttitle = {Recasting Nonlinear Differential Equations as {{S-systems}}},
  author = {Savageau, Michael A. and Voit, Eberhard O.},
  date = {1987-11},
  journaltitle = {Mathematical Biosciences},
  shortjournal = {Mathematical Biosciences},
  volume = {87},
  number = {1},
  pages = {83--115},
  issn = {00255564},
  doi = {10.1016/0025-5564(87)90035-6},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0025556487900356},
  urldate = {2024-03-07},
  abstract = {An enormous variety of nonlinear differential equations and functions have been recast exactly in the canonical form called an S-system. This is a system of nonlinear ordinary differential equations, each with the same structure: the change in a variable is equal to a difference of products of power-law functions. We review the development of S-systems, prove that the minimum for the range of equations that can be recast as S-systems consists of all equations composed of elementary functions and nested elementary functions of elementary functions, give a detailed example of the recasting process, and discuss the theoretical and practical implications. Among the latter is the ability to solve numerically nonlinear ordinary differential equations in their S-system form significantly faster than in their original form through utilization of a specially designed algorithm.},
  langid = {english}
}

@article{schmid_dynamic_2010,
  title = {Dynamic Mode Decomposition of Numerical and Experimental Data},
  author = {Schmid, Peter J.},
  date = {2010-08-10},
  journaltitle = {Journal of Fluid Mechanics},
  shortjournal = {J. Fluid Mech.},
  volume = {656},
  pages = {5--28},
  issn = {0022-1120, 1469-7645},
  doi = {10.1017/S0022112010001217},
  url = {https://www.cambridge.org/core/product/identifier/S0022112010001217/type/journal_article},
  urldate = {2024-04-17},
  abstract = {The description of coherent features of fluid flow is essential to our understanding of fluid-dynamical and transport processes. A method is introduced that is able to extract dynamic information from flow fields that are either generated by a (direct) numerical simulation or visualized/measured in a physical experiment. The extracted dynamic modes, which can be interpreted as a generalization of global stability modes, can be used to describe the underlying physical mechanisms captured in the data sequence or to project large-scale problems onto a dynamical system of significantly fewer degrees of freedom. The concentration on subdomains of the flow field where relevant dynamics is expected allows the dissection of a complex flow into regions of localized instability phenomena and further illustrates the flexibility of the method, as does the description of the dynamics within a spatial framework. Demonstrations of the method are presented consisting of a plane channel flow, flow over a two-dimensional cavity, wake flow behind a flexible membrane and a jet passing between two cylinders.},
  langid = {english}
}

@online{shi_deep_2022,
  title = {Deep {{Koopman Operator}} with {{Control}} for {{Nonlinear Systems}}},
  author = {Shi, Haojie and Meng, Max Q.-H.},
  date = {2022-06-15},
  eprint = {2202.08004},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2202.08004},
  urldate = {2023-12-01},
  abstract = {Recently Koopman operator has become a promising data-driven tool to facilitate real-time control for unknown nonlinear systems. It maps nonlinear systems into equivalent linear systems in embedding space, ready for real-time linear control methods. However, designing an appropriate Koopman embedding function remains a challenging task. Furthermore, most Koopman-based algorithms only consider nonlinear systems with linear control input, resulting in lousy prediction and control performance when the system is fully nonlinear with the control input. In this work, we propose an end-to-end deep learning framework to learn the Koopman embedding function and Koopman Operator together to alleviate such difficulties. We first parameterize the embedding function and Koopman Operator with the neural network and train them end-to-end with the K-steps loss function. Then, an auxiliary control network is augmented to encode the nonlinear state-dependent control term to model the nonlinearity in the control input. This encoded term is considered the new control variable instead to ensure linearity of the modeled system in the embedding system. We next deploy Linear Quadratic Regulator (LQR) on the linear embedding space to derive the optimal control policy and decode the actual control input from the control net. Experimental results demonstrate that our approach outperforms other existing methods, reducing the prediction error by order of magnitude and achieving superior control performance in several nonlinear dynamic systems like damping pendulum, CartPole, and the seven DOF robotic manipulator.},
  langid = {english},
  pubstate = {preprint}
}

@inproceedings{shi_neural_2019,
  title = {Neural {{Lander}}: {{Stable Drone Landing Control Using Learned Dynamics}}},
  shorttitle = {Neural {{Lander}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Shi, Guanya and Shi, Xichen and O’Connell, Michael and Yu, Rose and Azizzadenesheli, Kamyar and Anandkumar, Animashree and Yue, Yisong and Chung, Soon-Jo},
  date = {2019-05},
  pages = {9784--9790},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2019.8794351},
  url = {https://ieeexplore.ieee.org/abstract/document/8794351},
  urldate = {2024-05-01},
  abstract = {Precise near-ground trajectory control is difficult for multi-rotor drones, due to the complex aerodynamic effects caused by interactions between multi-rotor airflow and the environment. Conventional control methods often fail to properly account for these complex effects and fall short in accomplishing smooth landing. In this paper, we present a novel deep-learning-based robust nonlinear controller (Neural-Lander) that improves control performance of a quadrotor during landing. Our approach combines a nominal dynamics model with a Deep Neural Network (DNN) that learns high-order interactions. We apply spectral normalization (SN) to constrain the Lipschitz constant of the DNN. Leveraging this Lipschitz property, we design a nonlinear feedback linearization controller using the learned model and prove system stability with disturbance rejection. To the best of our knowledge, this is the first DNN-based nonlinear feedback controller with stability guarantees that can utilize arbitrarily large neural nets. Experimental results demonstrate that the proposed controller significantly outperforms a Baseline Nonlinear Tracking Controller in both landing and cross-table trajectory tracking cases. We also empirically show that the DNN generalizes well to unseen data outside the training domain.},
  eventtitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})}
}

@book{slotine_applied_1991,
  title = {Applied Nonlinear Control},
  author = {Slotine, J.-J. E. and Li, Weiping},
  date = {1991},
  publisher = {Prentice Hall},
  location = {Englewood Cliffs, N.J},
  isbn = {978-0-13-040890-7},
  langid = {english},
  pagetotal = {459}
}

@online{tedrake_underactuated_2023,
  title = {Underactuated {{Robotics}}},
  author = {Tedrake, Russ},
  date = {2023-06-29},
  url = {https://underactuated.csail.mit.edu/},
  urldate = {2022-12-08}
}

@article{tu_dynamic_2014,
  title = {On {{Dynamic Mode Decomposition}}: {{Theory}} and {{Applications}}},
  shorttitle = {On {{Dynamic Mode Decomposition}}},
  author = {Tu, Jonathan H. and Rowley, Clarence W. and Luchtenburg, Dirk M. and Brunton, Steven L. and Kutz, J. Nathan},
  date = {2014},
  journaltitle = {Journal of Computational Dynamics},
  shortjournal = {J. Comput. Dyn.},
  volume = {1},
  number = {2},
  eprint = {1312.0041},
  eprinttype = {arxiv},
  eprintclass = {physics},
  pages = {391--421},
  issn = {2158-2505},
  doi = {10.3934/jcd.2014.1.391},
  url = {http://arxiv.org/abs/1312.0041},
  urldate = {2024-04-17},
  abstract = {Originally introduced in the fluid mechanics community, dynamic mode decomposition (DMD) has emerged as a powerful tool for analyzing the dynamics of nonlinear systems. However, existing DMD theory deals primarily with sequential time series for which the measurement dimension is much larger than the number of measurements taken. We present a theoretical framework in which we define DMD as the eigendecomposition of an approximating linear operator. This generalizes DMD to a larger class of datasets, including nonsequential time series. We demonstrate the utility of this approach by presenting novel sampling strategies that increase computational efficiency and mitigate the effects of noise, respectively. We also introduce the concept of linear consistency, which helps explain the potential pitfalls of applying DMD to rank-deficient datasets, illustrating with examples. Such computations are not considered in the existing literature, but can be understood using our more general framework. In addition, we show that our theory strengthens the connections between DMD and Koopman operator theory. It also establishes connections between DMD and other techniques, including the eigensystem realization algorithm (ERA), a system identification method, and linear inverse modeling (LIM), a method from climate science. We show that under certain conditions, DMD is equivalent to LIM.},
  langid = {english}
}

@inproceedings{wagener_online_2019,
  title = {An {{Online Learning Approach}} to {{Model Predictive Control}}},
  author = {Wagener, Nolan and Cheng, Ching-an and Sacks, Jacob and Boots, Byron},
  date = {2019-06-22},
  volume = {15},
  url = {http://m.roboticsproceedings.org/rss15/p33.html},
  urldate = {2022-12-08},
  eventtitle = {Robotics: {{Science}} and {{Systems XV}}},
  isbn = {978-0-9923747-5-4}
}

@online{williams_kernelbased_2015,
  title = {A {{Kernel-Based Approach}} to {{Data-Driven Koopman Spectral Analysis}}},
  author = {Williams, Matthew O. and Rowley, Clarence W. and Kevrekidis, Ioannis G.},
  date = {2015-07-27},
  eprint = {1411.2260},
  eprinttype = {arxiv},
  eprintclass = {math},
  url = {http://arxiv.org/abs/1411.2260},
  urldate = {2024-03-07},
  abstract = {A data-driven, kernel-based method for approximating the leading Koopman eigenvalues, eigenfunctions, and modes in problems with highdimensional state spaces is presented. This approach approximates the Koopman operator using a set of scalar observables, which are functions that map states to scalars, that is determined implicitly by the choice of a kernel function. This circumvents the computational issues that arise due to the number of basis functions required to span a “sufficiently rich” subspace of the space of scalar observables in such applications. We illustrate this method on two examples: the FitzHugh-Nagumo PDE, a prototypical one-dimensional reaction-diffusion system, and vorticity data obtained from experimentally obtained velocity data for flow over a cylinder at Reynolds number 413. In both examples, we compare our results with related methods, such as Dynamic Mode Decomposition (DMD) that have the same cost as our approach.},
  langid = {english},
  pubstate = {preprint}
}
