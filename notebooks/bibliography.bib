@incollection{bensoussan_machine_2022,
  title = {Machine Learning and Control Theory},
  booktitle = {Handbook of {{Numerical Analysis}}},
  author = {Bensoussan, Alain and Li, Yiqun and Nguyen, Dinh Phan Cao and Tran, Minh-Binh and Yam, Sheung Chi Phillip and Zhou, Xiang},
  year = {2022},
  volume = {23},
  pages = {531--558},
  publisher = {Elsevier},
  doi = {10.1016/bs.hna.2021.12.016},
  urldate = {2023-12-19},
  abstract = {We survey in this article the connections between Machine Learning and Control Theory. Control Theory provide useful concepts and tools for Machine Learning. Conversely Machine Learning can be used to solve large control problems. In the first part of the paper, we develop the connections between reinforcement learning and Markov Decision Processes, which are discrete time control problems. In the second part, we review the concept of supervised learning and the relation with static optimization. Deep learning which extends supervised learning, can be viewed as a control problem. In the third part, we present the links between stochastic gradient descent and mean field theory. Conversely, in the fourth and fifth parts, we review machine learning approaches to stochastic control problems,and focus on the deterministic case, to explain, more easily, the numerical algorithms.},
  isbn = {978-0-323-85059-9},
  langid = {english}
}

@book{bertsekas_lessons_2022,
  title = {Lessons from {{AlphaZero}} for {{Optimal}}, {{Model Predictive}}, and {{Adaptive Control}}},
  author = {Bertsekas, Dimitri P},
  year = {2022},
  month = aug,
  abstract = {The purpose of this book is to propose and develop a new conceptual framework for approximate Dynamic Programming (DP) and Reinforcement Learning (RL). This framework centers around two algorithms, which are designed largely independently of each other and operate in synergy through the powerful mechanism of Newton's method. We call these the off-line training and the on-line play algorithms; the names are borrowed from some of the major successes of RL involving games. Primary examples are the recent (2017) AlphaZero program (which plays chess), and the similarly structured and earlier (1990s) TD-Gammon program (which plays backgammon). In these game contexts, the off-line training algorithm is the method used to teach the program how to evaluate positions and to generate good moves at any given position, while the on-line play algorithm is the method used to play in real time against human or computer opponents. Both AlphaZero and TD-Gammon were trained off-line extensively using neural networks and an approximate version of the fundamental DP algorithm of policy iteration. Yet the AlphaZero player that was obtained off-line is not used directly during on-line play (it is too inaccurate due to approximation errors that are inherent in off-line neural network training). Instead a separate on-line player is used to select moves, based on multistep lookahead minimization and a terminal position evaluator that was trained using experience with the off-line player. The on-line player performs a form of policy improvement, which is not degraded by neural network approximations. As a result, it greatly improves the performance of the off-line player. Similarly, TD-Gammon performs on-line a policy improvement step using one-step or two-step lookahead minimization, which is not degraded by neural network approximations. To this end it uses an off-line neural network-trained terminal position evaluator, and importantly it also extends its on-line lookahead by rollout (simulation with the one-step lookahead player that is based on the position evaluator). Significantly, the synergy between off-line training and on-line play also underlies Model Predictive Control (MPC), a major control system design methodology that has been extensively developed since the 1980s. This synergy can be understood in terms of abstract models of infinite horizon DP and simple geometrical constructions, and helps to explain the all-important stability issues within the MPC context. An additional benefit of policy improvement by approximation in value space, not observed in the context of games (which have stable rules and environment), is that it works well with changing problem parameters and on-line replanning, similar to indirect adaptive control. Here the Bellman equation is perturbed due to the parameter changes, but approximation in value space still operates as a Newton step. An essential requirement here is that a system model is estimated on-line through some identification method, and is used during the one-step or multistep lookahead minimization process. In this monograph we aim to provide insights (often based on visualization), which explain the beneficial effects of on-line decision making on top of off-line training. In the process, we will bring out the strong connections between the artificial intelligence view of RL, and the control theory views of MPC and adaptive control. Moreover, we will show that in addition to MPC and adaptive control, our conceptual framework can be effectively integrated with other important methodologies such as multiagent systems and decentralized control, discrete and Bayesian optimization, and heuristic algorithms for discrete optimization. One of our principal aims is to show, through the algorithmic ideas of Newton's method and the unifying principles of abstract DP, that the AlphaZero/TD-Gammon methodology of approximation in value space and rollout applies very broadly to deterministic and stochastic optimal control problems. Newton's method here is used for the solution of Bellman's equation, an operator equation that applies universally within DP with both discrete and continuous state and control spaces, as well as finite and infinite horizon.},
  isbn = {978-1-886529-17-5},
  langid = {english}
}

@article{bevanda_koopman_2021,
  title = {Koopman Operator Dynamical Models: {{Learning}}, Analysis and Control},
  shorttitle = {Koopman Operator Dynamical Models},
  author = {Bevanda, Petar and Sosnowski, Stefan and Hirche, Sandra},
  year = {2021},
  month = jan,
  journal = {Annual Reviews in Control},
  volume = {52},
  pages = {197--212},
  issn = {1367-5788},
  doi = {10.1016/j.arcontrol.2021.09.002},
  urldate = {2023-12-01},
  abstract = {The Koopman operator allows for handling nonlinear systems through a globally linear representation. In general, the operator is infinite-dimensional -- necessitating finite approximations -- for which there is no overarching framework. Although there are principled ways of learning such finite approximations, they are in many instances overlooked in favor of, often ill-posed and unstructured methods. Also, Koopman operator theory has long-standing connections to known system-theoretic and dynamical system notions that are not universally recognized. Given the former and latter realities, this work aims to bridge the gap between various concepts regarding both theory and tractable realizations. Firstly, we review data-driven representations (both unstructured and structured) for Koopman operator dynamical models, categorizing various existing methodologies and highlighting their differences. Furthermore, we provide concise insight into the paradigm's relation to system-theoretic notions and analyze the prospect of using the paradigm for modeling control systems. Additionally, we outline the current challenges and comment on future perspectives.}
}

@article{brunke_safe_2022,
  title = {Safe {{Learning}} in {{Robotics}}: {{From Learning-Based Control}} to {{Safe Reinforcement Learning}}},
  shorttitle = {Safe {{Learning}} in {{Robotics}}},
  author = {Brunke, Lukas and Greeff, Melissa and Hall, Adam W. and Yuan, Zhaocong and Zhou, Siqi and Panerati, Jacopo and Schoellig, Angela P.},
  year = {2022},
  month = may,
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {5},
  number = {1},
  pages = {411--444},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-042920-020211},
  urldate = {2023-10-16},
  abstract = {The last half decade has seen a steep rise in the number of contributions on safe learning methods for real-world robotic deployments from both the control and reinforcement learning communities. This article provides a concise but holistic review of the recent advances made in using machine learning to achieve safe decision-making under uncertainties, with a focus on unifying the language and frameworks used in control theory and reinforcement learning research. It includes learning-based control approaches that safely improve performance by learning the uncertain dynamics, reinforcement learning approaches that encourage safety or robustness, and methods that can formally certify the safety of a learned control policy. As data- and learning-based robot control methods continue to gain traction, researchers must understand when and how to best leverage them in real-world scenarios where safety is imperative, such as when operating in close proximityto humans. We highlight some of the open challenges that will drive the field of robot learning in the coming years, and emphasize the need for realistic physics-based benchmarks to facilitate fair comparisons between control and reinforcement learning approaches.},
  langid = {english}
}

@article{cerf_combining_2023,
  title = {Combining Neural Networks and Control: Potentialities, Patterns and Perspectives},
  shorttitle = {Combining Neural Networks and Control},
  author = {Cerf, Sophie and Rutten, {\'E}ric},
  year = {2023},
  month = jan,
  journal = {IFAC-PapersOnLine},
  series = {22nd {{IFAC World Congress}}},
  volume = {56},
  number = {2},
  pages = {9036--9049},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2023.10.134},
  urldate = {2023-12-19},
  abstract = {Machine learning tools are widely used for knowledge extraction, modeling, and decision tasks; a range of problems that Control Theory also tackles. Their relations have been largely explored by looking at stochastic control and Markov Decision Processes, due to the proximity of their formulations. However, novel links between machine learning and deterministic control are emerging; combining both approaches, e.g. by performing identification with learning, or controlling the training process. The recent flourishing literature is vast: there is a need to identify challenges, trends and opportunities on this interface. This survey contributes i) to the compared analysis of both fields. ii) Based on literature review, a categorization of combinations of learning and control is drawn. In the control framework, learning has been used for modeling, controllers tuning or adaptation, generating a controller or as a controller itself, for translating complex objectives, or checking controlled systems. Conversely, in the learning framework, control is used for tuning hyperparameters, selecting or generating training data, as the training or decision-making algorithm itself or to guarantee learning properties. iii) Finally, discussions on the literature open novel promising combinations to be explored, such as control of neural networks' training process.},
  langid = {english}
}

@book{goodwin_control_2000,
  title = {Control {{System Desig}}},
  author = {Goodwin, Graham C.},
  year = {2000},
  publisher = {CONTROL SYSTEM DESIG}
}

@misc{goyal_generalized_2024a,
  title = {Generalized {{Quadratic Embeddings}} for {{Nonlinear Dynamics}} Using {{Deep Learning}}},
  author = {Goyal, Pawan and Benner, Peter},
  year = {2024},
  month = jan,
  number = {arXiv:2211.00357},
  eprint = {2211.00357},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2024-03-07},
  abstract = {The engineering design process often relies on mathematical modeling that can describe the underlying dynamic behavior. In this work, we present a data-driven methodology for modeling the dynamics of nonlinear systems. To simplify this task, we aim to identify a coordinate transformation that allows us to represent the dynamics of nonlinear systems using a common, simple model structure. The advantage of a common simple model is that customized design tools developed for it can be applied to study a large variety of nonlinear systems. The simplest common model---one can think of --- is linear, but linear systems often fall short in accurately capturing the complex dynamics of nonlinear systems. In this work, we propose using quadratic systems as the common structure, inspired by the lifting principle. According to this principle, smooth nonlinear systems can be expressed as quadratic systems in suitable coordinates without approximation errors. However, finding these coordinates solely from data is challenging. Here, we leverage deep learning to identify such lifted coordinates using only data, enabling a quadratic dynamical system to describe the system's dynamics. Additionally, we discuss the asymptotic stability of these quadratic dynamical systems. We illustrate the approach using data collected from various numerical examples, demonstrating its superior performance with the existing well-known techniques.},
  archiveprefix = {arxiv},
  langid = {english}
}

@misc{goyal_guaranteed_2024,
  title = {Guaranteed {{Stable Quadratic Models}} and Their Applications in {{SINDy}} and {{Operator Inference}}},
  author = {Goyal, Pawan and Duff, Igor Pontes and Benner, Peter},
  year = {2024},
  month = jan,
  number = {arXiv:2308.13819},
  eprint = {2308.13819},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2024-03-07},
  abstract = {Scientific machine learning for inferring dynamical systems combines data-driven modeling, physics-based modeling, and empirical knowledge. It plays an essential role in engineering design and digital twinning. In this work, we primarily focus on an operator inference methodology that builds dynamical models, preferably in low-dimension, with a prior hypothesis on the model structure, often determined by known physics or given by experts. Then, for inference, we aim to learn the operators of a model by setting up an appropriate optimization problem.},
  archiveprefix = {arxiv},
  langid = {english}
}

@incollection{grune_nonlinear_2017,
  title = {Nonlinear {{Model Predictive Control}}},
  booktitle = {Nonlinear {{Model Predictive Control}}: {{Theory}} and {{Algorithms}}},
  author = {Gr{\"u}ne, Lars and Pannek, J{\"u}rgen},
  editor = {Gr{\"u}ne, Lars and Pannek, J{\"u}rgen},
  year = {2017},
  series = {Communications and {{Control Engineering}}},
  pages = {45--69},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-46024-6_3},
  urldate = {2023-10-07},
  abstract = {In this chapter, we introduce the nonlinear model predictive control algorithm in a rigorous way. We start by defining a basic NMPC algorithm for constant reference and continue by formalizing state and control constraints. Viability (or weak forward invariance) of the set of state constraints is introduced and the consequences for the admissibility of the NMPC-feedback law are discussed. After having introduced NMPC in a special setting, we describe various extensions of the basic algorithm, considering time varying reference solutions, terminal constraints, and costs and additional weights. Finally, we investigate the optimal control problem corresponding to this generalized setting and prove several properties, most notably the dynamic programming principle.},
  isbn = {978-3-319-46024-6},
  langid = {english}
}

@inproceedings{gu_qlmor_2009,
  title = {{{QLMOR}}: A New Projection-Based Approach for Nonlinear Model Order Reduction},
  shorttitle = {{{QLMOR}}},
  booktitle = {Proceedings of the 2009 {{International Conference}} on {{Computer-Aided Design}}},
  author = {Gu, Chenjie},
  year = {2009},
  month = nov,
  pages = {389--396},
  publisher = {ACM},
  address = {San Jose California},
  doi = {10.1145/1687399.1687474},
  urldate = {2024-03-07},
  abstract = {We present a new projection-based nonlinear model order reduction method, named QLMOR (MOR via quadratic-linear systems). QLMOR employs two novel ideas: (1) we show that DAEs (differentialalgebraic equations) with many commonly-encountered nonlinear kernels can be re-written equivalently into a special format, QLDAEs (quadratic-linear differential algebraic equations, i.e., DAEs that are quadratic in their state variables and linear in their inputs); (2) we adapt the moment-matching reduction technique of NORM[1] to reduce these QLDAEs into QLDAEs of much smaller size.},
  isbn = {978-1-60558-800-1},
  langid = {english}
}

@article{hewing_learningbased_2020,
  title = {Learning-{{Based Model Predictive Control}}: {{Toward Safe Learning}} in {{Control}}},
  shorttitle = {Learning-{{Based Model Predictive Control}}},
  author = {Hewing, Lukas and Wabersich, Kim P. and Menner, Marcel and Zeilinger, Melanie N.},
  year = {2020},
  month = may,
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {3},
  number = {1},
  pages = {269--296},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-090419-075625},
  urldate = {2023-10-16},
  abstract = {Recent successes in the field of machine learning, as well as the availability of increased sensing and computational capabilities in modern control systems, have led to a growing interest in learning and data-driven control techniques. Model predictive control (MPC), as the prime methodology for constrained control, offers a significant opportunity to exploit the abundance of data in a reliable manner, particularly while taking safety constraints into account. This review aims at summarizing and categorizing previous research on learning-based MPC, i.e., the integration or combination of MPC with learning methods, for which we consider three main categories. Most of the research addresses learning for automatic improvement of the prediction model from recorded data. There is, however, also an increasing interest in techniques to infer the parameterization of the MPC controller, i.e., the cost and constraints, that lead to the best closed-loop performance. Finally, we discuss concepts that leverage MPC to augment learning-based controllers with constraint satisfaction properties.},
  langid = {english}
}

@misc{https_,
  title = {{{https://epubs.siam.org/doi/pdf/10.1137/16M1062296}}},
  urldate = {2024-03-07},
  howpublished = {https://epubs.siam.org/doi/pdf/10.1137/16M1062296}
}

@misc{janner_modelbased_2019,
  type = {Blog},
  title = {Model-{{Based Reinforcement Learning}}: {{Theory}} and {{Practice}}},
  author = {Janner, Michael},
  year = {2019},
  month = dec,
  journal = {The Berkeley Artificial Intelligence Research Blog},
  urldate = {2022-12-08},
  howpublished = {https://bair.berkeley.edu/blog/2019/12/12/mbpo/},
  langid = {english}
}

@article{korda_linear_2018,
  title = {Linear Predictors for Nonlinear Dynamical Systems: {{Koopman}} Operator Meets Model Predictive Control},
  shorttitle = {Linear Predictors for Nonlinear Dynamical Systems},
  author = {Korda, Milan and Mezi{\'c}, Igor},
  year = {2018},
  month = jul,
  journal = {Automatica},
  volume = {93},
  pages = {149--160},
  issn = {0005-1098},
  doi = {10.1016/j.automatica.2018.03.046},
  urldate = {2024-03-07},
  abstract = {This paper presents a class of linear predictors for nonlinear controlled dynamical systems. The basic idea is to lift (or embed) the nonlinear dynamics into a higher dimensional space where its evolution is approximately linear. In an uncontrolled setting, this procedure amounts to numerical approximations of the Koopman operator associated to the nonlinear dynamics. In this work, we extend the Koopman operator to controlled dynamical systems and apply the Extended Dynamic Mode Decomposition (EDMD) to compute a finite-dimensional approximation of the operator in such a way that this approximation has the form of a linear controlled dynamical system. In numerical examples, the linear predictors obtained in this way exhibit a performance superior to existing linear predictors such as those based on local linearization or the so called Carleman linearization. Importantly, the procedure to construct these linear predictors is completely data-driven and extremely simple -- it boils down to a nonlinear transformation of the data (the lifting) and a linear least squares problem in the lifted space that can be readily solved for large data sets. These linear predictors can be readily used to design controllers for the nonlinear dynamical system using linear controller design methodologies. We focus in particular on model predictive control (MPC) and show that MPC controllers designed in this way enjoy computational complexity of the underlying optimization problem comparable to that of MPC for a linear dynamical system with the same number of control inputs and the same dimension of the state-space. Importantly, linear inequality constraints on the state and control inputs as well as nonlinear constraints on the state can be imposed in a linear fashion in the proposed MPC scheme. Similarly, cost functions nonlinear in the state variable can be handled in a linear fashion. We treat both the full-state measurement case and the input--output case, as well as systems with disturbances/noise. Numerical examples demonstrate the approach.1}
}

@article{lusch_deep_2018,
  title = {Deep Learning for Universal Linear Embeddings of Nonlinear Dynamics},
  author = {Lusch, Bethany and Kutz, J. Nathan and Brunton, Steven L.},
  year = {2018},
  month = nov,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {4950},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-07210-0},
  urldate = {2024-03-07},
  abstract = {Abstract             Identifying coordinate transformations that make strongly nonlinear dynamics approximately linear has the potential to enable nonlinear prediction, estimation, and control using linear theory. The Koopman operator is a leading data-driven embedding, and its eigenfunctions provide intrinsic coordinates that globally linearize the dynamics. However, identifying and representing these eigenfunctions has proven challenging. This work leverages deep learning to discover representations of Koopman eigenfunctions from data. Our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold. We identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. We also generalize Koopman representations to include a ubiquitous class of systems with continuous spectra. Our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding, while connecting our models to decades of asymptotics. Thus, we benefit from the power of deep learning, while retaining the physical interpretability of Koopman embeddings.},
  langid = {english}
}

@article{otto_koopman_2021,
  title = {Koopman {{Operators}} for {{Estimation}} and {{Control}} of {{Dynamical Systems}}},
  author = {Otto, Samuel E. and Rowley, Clarence W.},
  year = {2021},
  month = may,
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {4},
  number = {1},
  pages = {59--87},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-071020-010108},
  urldate = {2023-12-01},
  abstract = {A common way to represent a system's dynamics is to specify how the state evolves in time. An alternative viewpoint is to specify how functions of the state evolve in time. This evolution of functions is governed by a linear operator called the Koopman operator, whose spectral properties reveal intrinsic features of a system. For instance, its eigenfunctions determine coordinates in which the dynamics evolve linearly. This review discusses the theoretical foundations of Koopman operator methods, as well as numerical methods developed over the past two decades to approximate the Koopman operator from data, for systems both with and without actuation. We pay special attention to ergodic systems, for which especially effective numerical methods are available. For nonlinear systems with an affine control input, the Koopman formalism leads naturally to systems that are bilinear in the state and the input, and this structure can be leveraged for the design of controllers and estimators.},
  langid = {english}
}

@article{pan_physicsinformed_2020,
  title = {Physics-{{Informed Probabilistic Learning}} of {{Linear Embeddings}} of {{Non-linear Dynamics With Guaranteed Stability}}},
  author = {Pan, Shaowu and Duraisamy, Karthik},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Applied Dynamical Systems},
  volume = {19},
  number = {1},
  eprint = {1906.03663},
  primaryclass = {math, stat},
  pages = {480--509},
  issn = {1536-0040},
  doi = {10.1137/19M1267246},
  urldate = {2024-03-07},
  abstract = {The Koopman operator has emerged as a powerful tool for the analysis of nonlinear dynamical systems as it provides coordinate transformations to globally linearize the dynamics. While recent deep learning approaches have been useful in extracting the Koopman operator from a data-driven perspective, several challenges remain. In this work, we formalize the problem of learning the continuous-time Koopman operator with deep neural networks in a measure-theoretic framework. Our approach induces two types of models: differential and recurrent form, the choice of which depends on the availability of the governing equations and data. We then enforce a structural parameterization that renders the realization of the Koopman operator provably stable. A new autoencoder architecture is constructed, such that only the residual of the dynamic mode decomposition is learned. Finally, we employ mean-field variational inference (MFVI) on the aforementioned framework in a hierarchical Bayesian setting to quantify uncertainties in the characterization and prediction of the dynamics of observables. The framework is evaluated on a simple polynomial system, the Duffing oscillator, and an unstable cylinder wake flow with noisy measurements.},
  archiveprefix = {arxiv},
  langid = {english}
}

@article{proctor_generalizing_2018,
  title = {Generalizing {{Koopman Theory}} to {{Allow}} for {{Inputs}} and {{Control}}},
  author = {Proctor, Joshua L. and Brunton, Steven L. and Kutz, J. Nathan},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Applied Dynamical Systems},
  volume = {17},
  number = {1},
  pages = {909--930},
  issn = {1536-0040},
  doi = {10.1137/16M1062296},
  urldate = {2024-03-07},
  abstract = {We develop a new generalization of Koopman operator theory that incorporates the effects of inputs and control. Koopman spectral analysis is a theoretical tool for the analysis of nonlinear dynamical systems. Moreover, Koopman is intimately connected to dynamic mode decomposition (DMD), a method that discovers coherent, spatio-temporal modes from data, connects local-linear analysis to nonlinear operator theory, and importantly creates an equation-free architecture for the study of complex systems. For actuated systems, standard Koopman analysis and DMD are incapable of producing input-output models; moreover, the dynamics and the modes will be corrupted by external forcing. Our new theoretical developments extend Koopman operator theory to allow for systems with nonlinear input-output characteristics. We show how this generalization is rigorously connected to a recent development called dynamic mode decomposition with control. We demonstrate this new theory on nonlinear dynamical systems, including a standard susceptible-infectious-recovered model with relevance to the analysis of infectious disease data with mass vaccination (actuation).},
  langid = {english}
}

@article{qian_lift_2020,
  title = {Lift \& {{Learn}}: {{Physics-informed}} Machine Learning for Large-Scale Nonlinear Dynamical Systems},
  shorttitle = {Lift \& {{Learn}}},
  author = {Qian, Elizabeth and Kramer, Boris and Peherstorfer, Benjamin and Willcox, Karen},
  year = {2020},
  month = may,
  journal = {Physica D: Nonlinear Phenomena},
  volume = {406},
  pages = {132401},
  issn = {0167-2789},
  doi = {10.1016/j.physd.2020.132401},
  urldate = {2024-03-07},
  abstract = {We present Lift \& Learn, a physics-informed method for learning low-dimensional models for large-scale dynamical systems. The method exploits knowledge of a system's governing equations to identify a coordinate transformation in which the system dynamics have quadratic structure. This transformation is called a lifting map because it often adds auxiliary variables to the system state. The lifting map is applied to data obtained by evaluating a model for the original nonlinear system. This lifted data is projected onto its leading principal components, and low-dimensional linear and quadratic matrix operators are fit to the lifted reduced data using a least-squares operator inference procedure. Analysis of our method shows that the Lift \& Learn models are able to capture the system physics in the lifted coordinates at least as accurately as traditional intrusive model reduction approaches. This preservation of system physics makes the Lift \& Learn models robust to changes in inputs. Numerical experiments on the FitzHugh--Nagumo neuron activation model and the compressible Euler equations demonstrate the generalizability of our model.}
}

@article{rosolia_datadriven_2018,
  title = {Data-{{Driven Predictive Control}} for {{Autonomous Systems}}},
  author = {Rosolia, Ugo and Zhang, Xiaojing and Borrelli, Francesco},
  year = {2018},
  month = may,
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {1},
  number = {1},
  pages = {259--286},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-060117-105215},
  urldate = {2023-10-16},
  abstract = {In autonomous systems, the ability to make forecasts and cope with uncertain predictions is synonymous with intelligence. Model predictive control (MPC) is an established control methodology that systematically uses forecasts to compute real-time optimal control decisions. In MPC, at each time step an optimization problem is solved over a moving horizon. The objective is to find a control policy that minimizes a predicted performance index while satisfying operating constraints. Uncertainty in MPC is handled by optimizing over multiple uncertain forecasts. In this case, performance index and operating constraints take the form of functions defined over a probability space, and the resulting technique is called stochastic MPC. Our research over the past 10 years has focused on predictive control design methods that systematically handle uncertain forecasts in autonomous and semiautonomous systems. In the first part of this article, we present an overview of the approach we use, its main advantages, and its challenges. In the second part, we present our most recent results on data-driven predictive control. We show how to use data to efficiently formulate stochastic MPC problems and autonomously improve performance in repetitive tasks. The proposed framework is able to handle a large set of predicted scenarios in real time and learn from historical data.},
  langid = {english}
}

@article{savageau_recasting_1987,
  title = {Recasting Nonlinear Differential Equations as {{S-systems}}: A Canonical Nonlinear Form},
  shorttitle = {Recasting Nonlinear Differential Equations as {{S-systems}}},
  author = {Savageau, Michael A. and Voit, Eberhard O.},
  year = {1987},
  month = nov,
  journal = {Mathematical Biosciences},
  volume = {87},
  number = {1},
  pages = {83--115},
  issn = {00255564},
  doi = {10.1016/0025-5564(87)90035-6},
  urldate = {2024-03-07},
  abstract = {An enormous variety of nonlinear differential equations and functions have been recast exactly in the canonical form called an S-system. This is a system of nonlinear ordinary differential equations, each with the same structure: the change in a variable is equal to a difference of products of power-law functions. We review the development of S-systems, prove that the minimum for the range of equations that can be recast as S-systems consists of all equations composed of elementary functions and nested elementary functions of elementary functions, give a detailed example of the recasting process, and discuss the theoretical and practical implications. Among the latter is the ability to solve numerically nonlinear ordinary differential equations in their S-system form significantly faster than in their original form through utilization of a specially designed algorithm.},
  langid = {english}
}

@misc{shi_deep_2022,
  title = {Deep {{Koopman Operator}} with {{Control}} for {{Nonlinear Systems}}},
  author = {Shi, Haojie and Meng, Max Q.-H.},
  year = {2022},
  month = jun,
  number = {arXiv:2202.08004},
  eprint = {2202.08004},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-12-01},
  abstract = {Recently Koopman operator has become a promising data-driven tool to facilitate real-time control for unknown nonlinear systems. It maps nonlinear systems into equivalent linear systems in embedding space, ready for real-time linear control methods. However, designing an appropriate Koopman embedding function remains a challenging task. Furthermore, most Koopman-based algorithms only consider nonlinear systems with linear control input, resulting in lousy prediction and control performance when the system is fully nonlinear with the control input. In this work, we propose an end-to-end deep learning framework to learn the Koopman embedding function and Koopman Operator together to alleviate such difficulties. We first parameterize the embedding function and Koopman Operator with the neural network and train them end-to-end with the K-steps loss function. Then, an auxiliary control network is augmented to encode the nonlinear state-dependent control term to model the nonlinearity in the control input. This encoded term is considered the new control variable instead to ensure linearity of the modeled system in the embedding system. We next deploy Linear Quadratic Regulator (LQR) on the linear embedding space to derive the optimal control policy and decode the actual control input from the control net. Experimental results demonstrate that our approach outperforms other existing methods, reducing the prediction error by order of magnitude and achieving superior control performance in several nonlinear dynamic systems like damping pendulum, CartPole, and the seven DOF robotic manipulator.},
  archiveprefix = {arxiv},
  langid = {english}
}

@book{slotine_applied_1991,
  title = {Applied Nonlinear Control},
  author = {Slotine, J.-J. E. and Li, Weiping},
  year = {1991},
  publisher = {Prentice Hall},
  address = {Englewood Cliffs, N.J},
  isbn = {978-0-13-040890-7},
  langid = {english},
  lccn = {QA402.35 .S56 1990}
}

@misc{tedrake_underactuated_2023,
  title = {Underactuated {{Robotics}}},
  author = {Tedrake, Russ},
  year = {2023},
  month = jun,
  urldate = {2022-12-08},
  howpublished = {https://underactuated.csail.mit.edu/}
}

@inproceedings{wagener_online_2019,
  title = {An {{Online Learning Approach}} to {{Model Predictive Control}}},
  booktitle = {Robotics: {{Science}} and {{Systems XV}}},
  author = {Wagener, Nolan and Cheng, Ching-an and Sacks, Jacob and Boots, Byron},
  year = {2019},
  month = jun,
  volume = {15},
  urldate = {2022-12-08},
  isbn = {978-0-9923747-5-4}
}

@misc{williams_kernelbased_2015,
  title = {A {{Kernel-Based Approach}} to {{Data-Driven Koopman Spectral Analysis}}},
  author = {Williams, Matthew O. and Rowley, Clarence W. and Kevrekidis, Ioannis G.},
  year = {2015},
  month = jul,
  number = {arXiv:1411.2260},
  eprint = {1411.2260},
  primaryclass = {math},
  publisher = {arXiv},
  urldate = {2024-03-07},
  abstract = {A data-driven, kernel-based method for approximating the leading Koopman eigenvalues, eigenfunctions, and modes in problems with highdimensional state spaces is presented. This approach approximates the Koopman operator using a set of scalar observables, which are functions that map states to scalars, that is determined implicitly by the choice of a kernel function. This circumvents the computational issues that arise due to the number of basis functions required to span a ``sufficiently rich'' subspace of the space of scalar observables in such applications. We illustrate this method on two examples: the FitzHugh-Nagumo PDE, a prototypical one-dimensional reaction-diffusion system, and vorticity data obtained from experimentally obtained velocity data for flow over a cylinder at Reynolds number 413. In both examples, we compare our results with related methods, such as Dynamic Mode Decomposition (DMD) that have the same cost as our approach.},
  archiveprefix = {arxiv},
  langid = {english}
}
