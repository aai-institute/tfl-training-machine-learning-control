{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "hide_input": false,
    "init_cell": true,
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv",
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_ml_control\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "init_cell": true,
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scene__Initialization": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "init_cell": true,
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import numpy as np\n",
    "from training_ml_control.shortest_path_problem import (\n",
    "    create_shortest_path_graph,\n",
    "    plot_shortest_path_graph,\n",
    "    plot_all_paths_graph,\n",
    ")\n",
    "from training_ml_control.environments import (\n",
    "    create_grid_world_environment,\n",
    "    plot_grid_graph,\n",
    "    convert_graph_to_directed,\n",
    "    plot_grid_all_paths_graph,\n",
    "    simulate_environment,\n",
    ")\n",
    "from training_ml_control.nb_utils import (\n",
    "    show_video,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    ":::{figure} ./_static/images/aai-institute-cover.png\n",
    ":width: 90%\n",
    ":align: center\n",
    "---\n",
    "name: aai-institute\n",
    "---\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "Dynamic programming (DP) is a method that in general solves optimization problems that involve making a sequence of decisions (multi-stage decision making problems) by determining, for each decision, subproblems that can be solved similarily, such that an optimal solution of the original problem can be found from optimal solutions of subproblems. This method is based on *Bellman’s Principle of Optimality*:\n",
    "\n",
    "> An optimal policy has the property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.\n",
    "\n",
    "A problem is said to satisfy the Principle of Optimality if the sub-solutions of an optimal solution of the problem are themselves optimal solutions for their subproblems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{figure} _static/images/20_optimality_principle_graph.png\n",
    ":width: 50%\n",
    "Representation of optimality principle on a graph. *Taken from [this blog post](https://int8.io/bellman-equations-reinforcement-learning/)*.\n",
    "- **Black** arrows represent sequence of optimal policy actions – the one that is evaluated with the greatest value.\n",
    "- **Green** arrow is optimal policy first action (decision) – when applied it yields a subproblem with new initial state. Principle of optimality is\n",
    "  related to this subproblem optimal policy.\n",
    "- **Green** circle represents initial state for a subproblem (the original one or the one induced by applying first action)\n",
    "- **Red** circle represents terminal state – assuming our original parametrization it is the maze exit\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usually creativity is required before we can recognize that a particular problem can be cast effectively as a dynamic program and often subtle insights are necessary to restructure the formulation so that it can be solved effectively.\n",
    "\n",
    "Dynamic Programming is a very general solution method for problems which have these properties:\n",
    "\n",
    "- Optimal substructure (Principle of optimality applies)\n",
    "  - The optimal solution can be decomposed into subproblems, e.g., shortest path.\n",
    "- Overlapping subproblems\n",
    "  - The subproblems recur many times.\n",
    "  - The solutions can be cached and reused.\n",
    "- Additive cost function\n",
    "  - The cost function along a given path can be decomposed as the sum of cost functions for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is used across a wide variety of domains, e.g.\n",
    "\n",
    "- Scheduling algorithms\n",
    "- Graph algorithms (e.g., shortest path algorithms)\n",
    "- Graphical models in ML (e.g., Viterbi algorithm)\n",
    "- Bioinformatics (e.g., Sequence alignment, Protein folding)\n",
    "- Finance (e.g. Derivatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Time\n",
    "\n",
    "We define the **optimal cost-to-go function** (also known as **value function**) for any feasible $\\mathbf{x} \\in \\mathbf{X}$ as[^*]:\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}) := \\min_{u \\in \\mathbf{U}} J(\\mathbf{x}, \\mathbf{u})\n",
    "$$\n",
    "\n",
    "[^*]: for the sake of simplicity we will focus on the discrete-time case\n",
    "\n",
    "An admissible control sequence $\\mathbf{u}^*$ is called optimal, if\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}) = J(\\mathbf{x}, \\mathbf{u}^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinite Horizon\n",
    "\n",
    "Given the optimal cost-to-go for an infinite-horizon optimal control problem:\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}_0) = \\min_{\\mathbf{u} \\in \\mathbf{U}} J(\\mathbf{x}_0, \\mathbf{u}) = \\min_{u \\in \\mathbf{U}} \\left[ \\sum \\limits_{k = 0}^{\\infty} c(\\mathbf{x}_k, \\mathbf{u}_k) \\right]\n",
    "$$\n",
    "\n",
    "We can unroll the expression by one-step to obtain:\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}_0) = \\min_{\\mathbf{u} \\in \\mathbf{U}} \\left[ c(\\mathbf{x}_0, \\mathbf{u}_0) + \\min_{u \\in \\mathbf{U}} \\sum \\limits_{k = 1}^{\\infty} c(\\mathbf{x}_k, \\mathbf{u}_k) \\right]\n",
    "$$\n",
    "\n",
    "Which is equivalent to:\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}_0) = \\min_{u \\in \\mathbf{U}} \\left[ c(\\mathbf{x}_0, \\mathbf{u}_0) + V(\\mathbf{x}_1) \\right]\n",
    "$$\n",
    "\n",
    "If we now replace $\\mathbf{x}_1 = f(\\mathbf{x}_0, \\mathbf{u}_0)$ and then get rid of time indices we finally get:\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}) = \\min_{\\mathbf{u} \\in \\mathbf{U}} \\left[ c(\\mathbf{x}, \\mathbf{u}) + V(f(\\mathbf{x}, \\mathbf{u})) \\right]\n",
    "$$\n",
    "\n",
    "This equation is called the *Bellman equation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  DP Algorithm\n",
    "\n",
    "For every initial state $\\mathbf{x}_0$, the optimal cost is equal to $V(\\mathbf{x}_0)$, given by the last step of the following algorithm, which proceeds backward in time from stage $N-1$ to stage $0$:\n",
    "\n",
    "- Start with $V(\\mathbf{x}_N) = c(\\mathbf{x}_N)$\n",
    "- then for $k = \\{N - 1, \\dots, 0\\}$, let:\n",
    " \n",
    "  $$\n",
    "  V(\\mathbf{x}_k) = \\displaystyle \\min_{u \\in \\mathbf{U}} \\left[ c(\\mathbf{x}_k, \\mathbf{u}_k) + V(f(\\mathbf{x}_k, \\mathbf{u}_k)) \\right]\n",
    "  $$\n",
    "  \n",
    "Once the values $V(\\mathbf{x}_0), \\dots , V(\\mathbf{x}_N)$ have been obtained, we can use a forward algorithm to construct an optimal control sequence $\\{u_0^*, \\dots, u_{N-1}^*\\}$ and corresponding state trajectory $\\{x_1^∗, \\dots, x_{N}^*\\}$ for the given initial state $x_0$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^*_k = \\displaystyle  \\argmin_{u \\in \\mathbf{U}}\n",
    "\\left[ c(\\mathbf{x}_k, \\mathbf{u}_k) + V(f(\\mathbf{x}_k, \\mathbf{u}_k)) \\right].\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{figure} _static/images/20_dynamic_programming.png\n",
    ":width: 60%\n",
    "Illustration of the DP algorithm. The tail subproblem that starts at $x_k$ at time $k$ minimizes over\n",
    "$\\{u_k , \\dots , u_{N-1}\\}$ the \"cost-to-go\" from $k$ to $N$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Graph Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "G = create_shortest_path_graph()\n",
    "plot_shortest_path_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to travel from node A to node G at minimum cost. If the cost represents time then we want to find the shortest path from A to G.\n",
    "\n",
    "- Arrows (edges) indicate the possible movements.\n",
    "- Numbers on edges indicate the cost of moving along an edge.\n",
    "\n",
    "We can use Dynamic Programming to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by determining all possible paths first ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "We then compute the cost-to-go at each node to determine the shortest path.\n",
    "\n",
    "Each node in this new graph represents a state. We will start from the tail (the last states) and compute recursively the cost for each state transition.\n",
    "\n",
    "Let $c(n_1, n_2)$ the cost of moving from node $n_1$ to node $n_2$ and $V(n)$ be the optimal cost-to-go from node $n$. We have $$V({\\text{G}}) = 0$$.\n",
    "\n",
    "We start with nodes **F** and **E**:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "V(\\text{F}) &= c(\\text{F}, \\text{G}) + V({\\text{G}}) &= 1 + 0 &= 1\\\\\n",
    "V(\\text{E}) &= c(\\text{E}, \\text{G}) + V({\\text{G}}) &= 1 + 0 &= 1\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We then move to nodes **D** and **C**:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "V(\\text{D}) &= \\min \\left[ c(\\text{D}, \\text{G}) + V({\\text{G}}), c(\\text{D}, \\text{F}) + V(\\text{F}) \\right]\n",
    "&= \\min \\left[ 8 + 0, 5 + 1 \\right] &= 6\n",
    "\\\\\n",
    "V(\\text{C}) &= c(\\text{C}, \\text{F}) + V({\\text{F}}) &= 2 + 1 &= 1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "After that we move to node **B**:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "V(\\text{B}) &= \\min \\left[ c(\\text{B}, \\text{D}) + V({\\text{D}}), c(\\text{B}, \\text{E}) + V(\\text{E}) \\right]\n",
    "&= \\min \\left[ 9 + 6, 1 + 1 \\right] &= 2\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We finally go to node **A**:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "V(\\text{A}) &= \\min \\left[\n",
    "c(\\text{A}, \\text{B}) + V(\\text{B}), c(\\text{A}, \\text{C}) + V(\\text{C}), c(\\text{A}, \\text{D}) + V(\\text{D})\n",
    "\\right]\n",
    "&= \\min \\left[ 4 + 2, 5 + 3, 3 + 6 \\right] &= 6\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Now that we have computed the optimal cost-to-go, we can proceed in a forward manner to determine the best path:\n",
    "\n",
    "$$\n",
    "\\pi^* = \\underset{n}{\\argmin} [c(n_1, n_2) + V(n_2)]\n",
    "$$\n",
    "\n",
    "For the first action (step) we have:\n",
    "\n",
    "$$\n",
    "\\pi^*_0 &= \\underset{n_2 \\in \\{ B, C, D \\}}{\\argmin} \\left[ c(A, n_2) + V(n_2) \\right] \\\\ \n",
    "&= \\underset{n_2}{\\argmin} \\left[ c(A, n_2 = B) + V(n_2 = B), c(A, n_2 = C) + V(n_2 = C), c(A, n_2 = D) + V(n_2 = D) \\right] \\\\\n",
    "&= \\underset{n_2}{\\argmin} \\left[ 4 + 2, 5 + 3, 3 + 6 \\right] \\\\\n",
    "&= B\n",
    "$$\n",
    "\n",
    "Proceeding the same way we get:\n",
    "\n",
    "$$\n",
    "\\pi^* &= \\{\\pi^*_0, \\pi^*_1, \\pi^*_2\\} &= \\{\\text{B, E, G} \\}\n",
    "$$\n",
    "\n",
    "The shortest-path is ABEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G, show_solution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "Another way to compute the optimal cost-to-go for all states that is also applicable is the **Value Iteration** algorithm:\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "  \\textbf{Input}:\\ \\text{MDP}\\ M = \\langle S, s_0, U, c(s, u)\\rangle\\\\\n",
    "  \\textbf{Output}:\\ \\text{Value function}\\ V\\\\[2mm]\n",
    "  \\text{Set}\\ V\\ \\text{to arbitrary value function; e.g., }\\ V(s) = 0\\ \\text{for all}\\ s\\\\[2mm]\n",
    "  \\text{repeat}\\ \\\\\n",
    "  \\quad\\quad \\Delta \\leftarrow 0 \\\\\n",
    "  \\quad\\quad \\text{foreach}\\ s \\in S \\\\\n",
    "  \\quad\\quad\\quad\\quad \\underbrace{V'(s) \\leftarrow \\min_{u \\in U(s)} \\left[c(s, u) + \\ V(s') \\right]}_{\\text{Bellman equation}} \\\\\n",
    "  \\quad\\quad\\quad\\quad \\Delta \\leftarrow \\min(\\Delta, |V'(s) - V(s)|) \\\\\n",
    "  \\quad\\quad V \\leftarrow V' \\\\\n",
    "  \\text{until}\\ \\Delta \\leq 0.0 \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    ":::{note} Stochastic Value Iteration\n",
    ":class:dropdown\n",
    "\n",
    "It can also be used in stochastic systems:\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "  \\textbf{Input}:\\ \\text{MDP}\\ M = \\langle S, s_0, U, P_u(s' \\mid s), c(s, u, s')\\rangle\\\\\n",
    "  \\textbf{Output}:\\ \\text{Value function}\\ V\\\\[2mm]\n",
    "  \\text{Set}\\ V\\ \\text{to arbitrary value function; e.g., }\\ V(s) = 0\\ \\text{for all}\\ s\\\\[2mm]\n",
    "  \\text{repeat}\\ \\\\\n",
    "  \\quad\\quad \\Delta \\leftarrow 0 \\\\\n",
    "  \\quad\\quad \\text{foreach}\\ s \\in S \\\\\n",
    "  \\quad\\quad\\quad\\quad \\underbrace{V'(s) \\leftarrow \\min_{u \\in U(s)} \\sum_{s' \\in S}  P_a(s' \\mid s)\\ [r(s,a,s') + \n",
    " \\gamma\\ V(s') ]}_{\\text{Bellman equation}} \\\\\n",
    "  \\quad\\quad\\quad\\quad \\Delta \\leftarrow \\min(\\Delta, |V'(s) - V(s)|) \\\\\n",
    "  \\quad\\quad V \\leftarrow V' \\\\\n",
    "  \\text{until}\\ \\Delta \\leq \\theta \n",
    "\\end{array}\n",
    "$$\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Control as Graph Search\n",
    "\n",
    "We can formulate discrete-time optimal control problems as graph search problems by either considering a system with discrete states and actions or by discretizing a system with continuous states and actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{exercise-start} Grid World\n",
    ":label: grid-world\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe width=\"800\" height=\"600\" src=\"https://www.youtube-nocookie.com/embed/p178eQpDI_E?si=7wzD4d1TIVj29WG0&amp;start=4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_grid_world_environment(render_mode=\"rgb_array\", max_steps=50)\n",
    "result = simulate_environment(env)\n",
    "show_video(result.frames, fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task can be represented as the following undirected graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "G = env.unwrapped.get_graph()\n",
    "plot_grid_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the graph to a directed graph with all possible paths from start to target that do not contain cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = convert_graph_to_directed(G)\n",
    "plot_grid_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish for the car to travel from its starting cell in red to the target cell in green. If the cost represents time and each step has the same cost then we want to find the shortest path to the goal.\n",
    "\n",
    "- Arrows (edges) indicate the possible movements.\n",
    "- Numbers on edges indicate the cost of moving along an edge.\n",
    "\n",
    "Use Dynamic Programming to solve this problem:\n",
    "\n",
    "- Determine the number of possible paths from start position to target position.\n",
    "- Compute the optimal cost-to-go for each state.\n",
    "- Determine the optimal plan using the computed optimal cost-to-go.\n",
    "- Implement the plan in the environment.\n",
    "\n",
    ":::{tip} Hint 1\n",
    ":class: dropdown\n",
    "Determine all possible paths first.\n",
    "\n",
    "You can use `plot_grid_all_paths_graph(G)` for that.\n",
    ":::\n",
    "\n",
    ":::{tip} Hint 2\n",
    ":class: dropdown\n",
    "Compute the optimal cost-to-go at each node.\n",
    "\n",
    "You can use `dict(G.nodes(data=True))` to get a dictionary that maps the nodes to their attributes\n",
    "and you can use `G.start_node` and `G.target_node` to access the start and end (i.e. goal) nodes, respectively.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{solution-start} grid-world\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{solution} grid-world\n",
    ":class: dropdown\n",
    "\n",
    "For this solution we first need to import some functions:\n",
    "\n",
    "```{code-cell}\n",
    "from training_ml_control.environments import (\n",
    "    value_iteration,\n",
    "    compute_best_path_and_actions_from_values,\n",
    ")\n",
    "import networkx as nx\n",
    "```\n",
    "\n",
    "To determine the number of paths from start node to target node we use:\n",
    "\n",
    "```{code-cell}\n",
    "len(list(nx.all_simple_paths(G.to_undirected(), source=G.start_node, target=G.target_node, cutoff=len(G))))\n",
    "```\n",
    "\n",
    "After that, to plot all paths from start to end we use:\n",
    "\n",
    "```{code-cell} python3\n",
    "plot_grid_all_paths_graph(G)\n",
    "```\n",
    "\n",
    "To compute the optimal cost-to-go we use:\n",
    "\n",
    "```{code-cell}\n",
    "values = value_iteration(G)\n",
    "```\n",
    "\n",
    "Once that's computed, we can determine the best path and correponding actions:\n",
    "\n",
    "```{code-cell}\n",
    "best_path, actions = compute_best_path_and_actions_from_values(G, start_node=G.start_node, target_node=G.target_node, values=values)\n",
    "print(f\"{best_path=}\")\n",
    "print(f\"{actions=}\")\n",
    "```\n",
    "\n",
    "We finally apply the computed plan to the environment and check that it indeed works:\n",
    "\n",
    "```{code-cell} python3\n",
    "env.reset()\n",
    "for action in actions:\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        frames = env.render()\n",
    "        env.reset()\n",
    "        break\n",
    "env.close()\n",
    "show_video(frames, fps=3)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Time\n",
    "\n",
    "Let's consider a continuous-time optimal control problem with finite horizon over the time period $[t_0 ,t_f]$.\n",
    "\n",
    "The system's dynamics is given by:\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}}(t) = f(\\mathbf{x}(t), \\mathbf{u}(t))\n",
    "$$\n",
    "\n",
    "With the initial state $\\mathbf{x}(t_0) = \\mathbf{x}_0$\n",
    "\n",
    "The cost-to-go is given by:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{x}(t), \\mathbf{u}(t), t_0, t_f) = c_f(\\mathbf{x}(t_f), t_f) + \\int\\limits_{t_0}^{t_f} c(\\mathbf{x}(t), \\mathbf{u}(t)) d\\tau\n",
    "$$\n",
    "\n",
    "The optimal cost-to-go is given by:\n",
    "\n",
    "$$\n",
    "\\displaystyle V(\\mathbf{x}(t), t_0, t_f) = \\underset{\\mathbf{u(t)}}{min} \\left[ J(\\mathbf{x}(t), \\mathbf{u}(t), t_0, t_f) \\right]\n",
    "$$\n",
    "\n",
    "It can be show that for every $s, \\tau \\in [t_0, t_f]$, $s \\leq \\tau$ , and $\\mathbf{x} \\in \\mathbf{X}$, we have:\n",
    "\n",
    "$$\n",
    "V(s, \\mathbf{x}) = \\underset{\\mathbf{u(t)}}{min} \\left[ \\int\\limits_{s}^{\\tau} c(\\mathbf{x}(t), \\mathbf{u}(t)) d\\tau + V(\\tau, \\mathbf{x}(\\tau)) \\right]\n",
    "$$\n",
    "\n",
    "Which is another version of the Bellman equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamilton-Jacobi-Bellman Equation\n",
    "\n",
    "The Hamilton-Jacobi-Bellman (HJB) equation is given by:\n",
    "\n",
    "$$\n",
    "- \\frac{\\partial V}{\\partial t} = \\underset{\\mathbf{u(t)}}{min} \\left[ \\left( \\frac{\\partial V}{\\partial \\mathbf{x}} \\right)^T f(\\mathbf{x}(t), \\mathbf{u}(t)) + c(\\mathbf{x}(t), \\mathbf{u}(t)) \\right]\n",
    "$$\n",
    "\n",
    "It is a sufficient condition of optimality i.e., that if $V$ satisfies the HJB, it must be the value function."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "scenes_data": {
   "active_scene": "Initialization",
   "init_scene": "Initialization",
   "scenes": [
    "Initialization"
   ]
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
