{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "hide_input": false,
    "init_cell": true,
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv",
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_ml_control\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "init_cell": true,
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scene__Initialization": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "init_cell": true,
    "scene__Initialization": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import casadi\n",
    "import do_mpc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from do_mpc.controller import MPC\n",
    "from do_mpc.simulator import Simulator\n",
    "from do_mpc.model import Model\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from training_ml_control.control import (\n",
    "    build_mpc_controller,\n",
    ")\n",
    "\n",
    "from training_ml_control.plots import (\n",
    "    plot_cart_results,\n",
    "    plot_inverted_pendulum_results,\n",
    ")\n",
    "\n",
    "from training_ml_control.environments import (\n",
    "    create_cart_environment,\n",
    "    create_inverted_pendulum_environment,\n",
    "    simulate_environment,\n",
    ")\n",
    "from training_ml_control.plots import (\n",
    "    animate_cart_simulation,\n",
    "    animate_inverted_pendulum_simulation,\n",
    "    animate_full_inverted_pendulum_simulation,\n",
    ")\n",
    "from training_ml_control.control import (\n",
    "    build_lqr_controller,\n",
    ")\n",
    "from training_ml_control.model import (\n",
    "    build_cart_model,\n",
    "    build_inverted_pendulum_linear_model,\n",
    "    build_inverted_pendulum_nonlinear_model,\n",
    ")\n",
    "\n",
    "from training_ml_control.nb_utils import (\n",
    "    display_array,\n",
    "    show_video,\n",
    ")\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = [9, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    ":::{figure} ./_static/images/aai-institute-cover.png\n",
    ":width: 90%\n",
    ":align: center\n",
    "---\n",
    "name: aai-institute\n",
    "---\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Unfortunately, the analytically convenient linear quadratic problem formulations are often not satisfactory. There are two main reasons for this:\n",
    "\n",
    "- The system may be nonlinear, and it may be inappropriate to use for\n",
    "  control purposes. Moreover, some of the control variables may be naturally\n",
    "  discrete, and this is incompatible with the linear system viewpoint.\n",
    "  \n",
    "- There may be control and/or state constraints, which are not handled\n",
    "  adequately through quadratic penalty terms in the cost function. For\n",
    "  example, the motion of a car may be constrained by the presence of\n",
    "  obstacles and hardware limitations.\n",
    "  The solution obtained from a linear quadratic model may not be suitable for such\n",
    "  a problem, because quadratic penalties treat constraints \"softly\"\n",
    "  and may produce trajectories that violate the constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Model Predictive Control (**MPC**), also referred to as *Receding Horizon Control and Moving Horizon Optimal Control*, is a control algorithm based on solving an **on-line** optimal control problem. A receding horizon approach is used which can be summarized in the following steps:\n",
    "\n",
    "1. At time $t$ and for the current state $x_t$, solve, on-line, an open-loop optimal control problem over some future interval taking account the current and future constraints.\n",
    "2. Apply the first step in the optimal control sequence.\n",
    "3. Repeat the procedure at time $t + 1$ using the current state $x_{t + 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{figure} _static/images/40_model_predictive_control_horizon.svg\n",
    ":width: 50%\n",
    "\n",
    "Illustration of the problem solved by MPC at state $x_k$.\n",
    "We minimize the cost function over the next $l$ stages.\n",
    "We then apply the control of the optimizing sequence up to the control horizon.\n",
    "In most cases, the control horizon is set to 1.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{figure} _static/images/40_mpc_block_diagram_2.png\n",
    ":width: 60%\n",
    "MPC Block Diagram.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A major difference between MPC and finite-state stochastic control problems\n",
    "that are popular in the RL/artificial intelligence literature is that in MPC\n",
    "the state and control spaces are continuous/infinite, such as for example\n",
    "in self-driving cars, the control of aircraft and drones, or the operation of\n",
    "chemical processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?? build_mpc_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`build_mpc_controller` does the following:\n",
    "\n",
    "- First, it creates an instance of the MPC class is generated with the passeed model.\n",
    "- It configures this object with parameters such as the time step and the horizon as well as parameters that are specific to the solver we are using.\n",
    "- It then sets the control objective using the passed terminal and stage costs.\n",
    "- It also restricts the input force by adding an optional penalty.\n",
    "- After that, it sets upper and lower limits for the state and force.\n",
    "- Finally, it sets everything up and returns the controller object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[do-mpc](https://www.do-mpc.com/en/latest/), the package we're using in this training, uses [CasADi](https://web.casadi.org/python-api/) (an open-source tool for nonlinear optimization and algorithmic differentiation) for the modeling part and for the different cost functions. Here's a table of useful operators:\n",
    "\n",
    "| Operator | Description |Equation |\n",
    "| --- | --- | --- |\n",
    "| [casadi.sumsqr(x)](https://web.casadi.org/python-api/#casadi.casadi.sumsqr) | Squared-sum | $\\sum x_i^2$ |\n",
    "| [casadi.norm_2(x)](https://web.casadi.org/python-api/#casadi.casadi.norm_2) | $L_2$-norm | $\\sqrt{\\sum x_i^2}$ |\n",
    "| [casadi.norm_1(x)](https://web.casadi.org/python-api/#casadi.casadi.norm_1) | $L_1$-norm | $\\sum|x_i|$ |\n",
    "| [casadi.bilin(A, x)](https://web.casadi.org/python-api/#casadi.casadi.bilin) | Quadratic Form | $x^T A x$ |\n",
    "| [casadi.bilin(A, x, y)](https://web.casadi.org/python-api/#casadi.casadi.bilin) | Bilinear Form | $x^T A y$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cart\n",
    "\n",
    "Now, we design an MPC controller for the Cart system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cart_env = create_cart_environment(goal_position=9)\n",
    "cart_model = build_cart_model(cart_env)\n",
    "cart_simulator = Simulator(cart_model)\n",
    "cart_simulator.set_param(t_step=cart_env.dt)\n",
    "cart_simulator.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The control objective is to move the cart to a desired position (`9`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoint = np.array([cart_env.goal_position, 1.0])\n",
    "distance_cost = 100 * casadi.norm_2(cart_model.x.cat - setpoint)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "display_array(\"Setpoint\", setpoint)\n",
    "print(f\"Stage Cost = {stage_cost}\")\n",
    "print(f\"Terminal Cost = {terminal_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also restrict the input force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "force_penalty = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define as well upper and lower limits for the state and force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_limits = np.array([-10, 10])\n",
    "u_limits = np.array([-30, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create an instance of `MPC` from the `do_mpc` package using the already defined `build_mpc_controller` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_mpc_controller = build_mpc_controller(\n",
    "    model=cart_model,\n",
    "    t_step=cart_env.dt,\n",
    "    n_horizon=10,\n",
    "    stage_cost=stage_cost,\n",
    "    terminal_cost=terminal_cost,\n",
    "    force_penalty=force_penalty,\n",
    "    x_limits=x_limits,\n",
    "    u_limits=u_limits,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simulation\n",
    "\n",
    "We set the initial state and simulate the closed-loop for 100 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "cart_mpc_controller.reset_history()\n",
    "cart_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "cart_simulator.x0 = x0\n",
    "cart_mpc_controller.x0 = x0\n",
    "cart_mpc_controller.set_initial_guess()\n",
    "\n",
    "for k in range(100):\n",
    "    u = cart_mpc_controller.make_step(x0)\n",
    "    x0 = cart_simulator.make_step(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_cart_simulation(cart_mpc_controller.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation\n",
    "\n",
    "Finally, we evaluate the controller on the actual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(2)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return self.mpc.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 200\n",
    "controller = MPCController(cart_mpc_controller)\n",
    "results = simulate_environment(cart_env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "show_video(results.frames, fps=1 / cart_env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "T = np.arange(len(results.observations)) * cart_env.dt\n",
    "plot_cart_results(\n",
    "    T=T,\n",
    "    observations=results.observations,\n",
    "    actions=results.actions,\n",
    "    reference=cart_env.goal_position,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise} Linear Inverted Pendulum MPC\n",
    ":label: inverted-pendulum-linear-mpc\n",
    "\n",
    "- Design an MPC controller for linearized inverted pendulum model to keep the pole upright by following these steps:\n",
    "  1. Define stage and terminal costs.\n",
    "  1. Define setpoint $\\begin{bmatrix}\\theta_s \\\\ \\dot{\\theta}_s\\end{bmatrix} = \\begin{bmatrix}0.0 \\\\ 0.0 \\end{bmatrix}$.\n",
    "  1. Define appropriate force penalty.\n",
    "  1. Create an mpc controller by calling the `build_mpc_controller` function and passing the appropriate arguments.\n",
    "  1. Simulate the system using the simulator and the controller.\n",
    "  1. Evaluate the controller on the environment.\n",
    "- For each case, try different cost functions:\n",
    "  - $\\sum \\theta^2$\n",
    "  - $\\sum |\\theta|$\n",
    "  - $E_{\\text{kinetic}} - E_{\\text{potential}}$\n",
    "\n",
    ":::{hint}\n",
    "You can access the inverted pendulum's kinetic, respectively potential, energy using `inverted_pendulum_lin_model.aux[\"E_kinetic\"]`, respectively `inverted_pendulum_lin_model.aux[\"E_potential\"]`)\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "::::{solution} inverted-pendulum-linear-mpc\n",
    ":class: dropdown\n",
    "\n",
    "We first need the environment, linear model and simulator:\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "inverted_pendulum_env = create_inverted_pendulum_environment(max_steps=200)\n",
    "inverted_pendulum_lin_model = build_inverted_pendulum_linear_model(inverted_pendulum_env)\n",
    "inverted_pendulum_lin_simulator = Simulator(inverted_pendulum_lin_model)\n",
    "inverted_pendulum_lin_simulator.set_param(t_step=inverted_pendulum_env.dt)\n",
    "inverted_pendulum_lin_simulator.setup()\n",
    ":::\n",
    "\n",
    "The goal is to keep the inverted pendulum upright. For that we define the following costs, setpoint and force penalty:\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "setpoint = np.zeros((2, 1))\n",
    "distance_cost = casadi.bilin(np.diag([100, 1]), inverted_pendulum_lin.x.cat - setpoint)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "force_penalty = 1e-2\n",
    "display_array(\"Setpoint\", setpoint)\n",
    "print(f\"{stage_cost=}\")\n",
    "print(f\"{terminal_cost=}\")\n",
    ":::\n",
    "\n",
    "We define as well upper and lower limits for the state and force\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "x_limits = np.array([-np.inf, np.inf])\n",
    "u_limits = np.array([-inverted_pendulum_env.force_max, inverted_pendulum_env.force_max])\n",
    ":::\n",
    "\n",
    "After that, we create the controller:\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "inverted_pendulum_mpc_controller = build_mpc_controller(\n",
    "    model=inverted_pendulum_lin_model,\n",
    "    t_step=inverted_pendulum_env.dt,\n",
    "    n_horizon=100,\n",
    "    stage_cost=stage_cost,\n",
    "    terminal_cost=terminal_cost,\n",
    "    force_penalty=force_penalty,\n",
    "    x_limits=x_limits,\n",
    "    u_limits=u_limits,\n",
    ")\n",
    ":::\n",
    "\n",
    "#### Simulation\n",
    " \n",
    ":::{code-cell} ipython3\n",
    "inverted_pendulum_mpc_controller.reset_history()\n",
    "inverted_pendulum_lin_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "x0[0] = 0.01\n",
    "inverted_pendulum_simulator.x0 = x0\n",
    "\n",
    "for k in range(50):\n",
    "    u0 = inverted_pendulum_mpc_controller.make_step(x0)\n",
    "    x0 = inverted_pendulum_lin_simulator.make_step(u0)\n",
    "\n",
    "animate_inverted_pendulum_simulation(inverted_pendulum_mpc_controller.data)\n",
    ":::\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(2)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation[[2, 3]].reshape(-1, 1)).ravel()\n",
    ":::\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "mpc_controller = MPCController(inverted_pendulum_mpc_controller)\n",
    "results = simulate_environment(inverted_pendulum_mpc_controller, max_steps=200, controller=mpc_controller)\n",
    "show_video(results.frames, fps=1 / inverted_pendulum_env.dt)\n",
    ":::\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "plt.close()\n",
    "T = np.arange(len(results.observations)) * inverted_pendulum_env.dt\n",
    "plot_inverted_pendulum_results(T=T, observations=results.observations, actions=results.actions, reference=np.inf);\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise} Non-Linear Inverted Pendulum MPC\n",
    ":label: non-linear-inverted-pendulum-mpc\n",
    "\n",
    "- Design an MPC Controller for the non-linear inverted pendulum system for two different cases:\n",
    "  1. Cart at origin and upright Pendulum: Set the reference for the cart position to the origin.\n",
    "  2. Pendulum Swing-up: Set the initial angle to to $-\\pi$ i.e. start with the pendulum at the bottom.\n",
    "  3. Same as 2 but set the reference for the cart position to the origin.\n",
    "  4. Make the pendulum rotate as fast as possible.\n",
    "\n",
    ":::{hint}\n",
    "Use the following to create the environment with initial angle set to -np.pi and cutoff angle to np.inf for second > case.\n",
    "\n",
    "```{code-cell} ipython3\n",
    "env = create_inverted_pendulum_environment(theta_threshold=np.inf, initial_angle=-np.pi)\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{hint}\n",
    "You can access the inverted pendulum's kinetic, respectively potential, energy using `inverted_pendulum_lin_model.aux[\"E_kinetic\"]`, respectively `inverted_pendulum_lin_model.aux[\"E_potential\"]`)\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{solution} non-linear-inverted-pendulum-mpc\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{solution} non-linear-inverted-pendulum-mpc\n",
    ":class: dropdown\n",
    "\n",
    "#### Fast Rotation\n",
    "\n",
    "We first need the environment, non-linear model and simulator:\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "inverted_pendulum_env = create_inverted_pendulum_environment(max_steps=200)\n",
    "inverted_pendulum_nonlin_model = build_inverted_pendulum_nonlinear_model(inverted_pendulum_env)\n",
    "inverted_pendulum_nonlin_simulator = Simulator(inverted_pendulum_nonlin_model)\n",
    "inverted_pendulum_nonlin_simulator.set_param(t_step=inverted_pendulum_env.dt)\n",
    "inverted_pendulum_nonlin_simulator.setup()\n",
    ":::\n",
    "\n",
    "The goal is to keep the inverted pendulum upright. For that we define the following costs and force penalty:\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "rotation_cost = - 1000 * inverted_pendulum_nonlin_model.x[3]\n",
    "terminal_cost = rotation_cost\n",
    "stage_cost = rotation_cost\n",
    "force_penalty = 0.0\n",
    "print(f\"{stage_cost=}\")\n",
    "print(f\"{terminal_cost=}\")\n",
    ":::\n",
    "\n",
    "We define as well upper and lower limits for the state and force\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "x_limits = np.array([-np.inf, np.inf])\n",
    "u_limits = np.array([-inverted_pendulum_env.force_max, inverted_pendulum_env.force_max])\n",
    ":::\n",
    "\n",
    "After that, we create the controller:\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "inverted_pendulum_mpc_controller = build_mpc_controller(\n",
    "    model=inverted_pendulum_nonlin_model,\n",
    "    t_step=inverted_pendulum_env.dt,\n",
    "    n_horizon=100,\n",
    "    stage_cost=stage_cost,\n",
    "    terminal_cost=terminal_cost,\n",
    "    force_penalty=force_penalty,\n",
    "    x_limits=x_limits,\n",
    "    u_limits=u_limits,\n",
    ")\n",
    ":::\n",
    "\n",
    "#### Simulation\n",
    " \n",
    ":::{code-cell} ipython3\n",
    "inverted_pendulum_mpc_controller.reset_history()\n",
    "inverted_pendulum_nonlin_simulator.reset_history()\n",
    "x0 = np.zeros((4, 1))\n",
    "x0[2] = 0.01\n",
    "inverted_pendulum_nonlin_simulator.x0 = x0\n",
    "\n",
    "for k in range(50):\n",
    "    u0 = inverted_pendulum_mpc_controller.make_step(x0)\n",
    "    x0 = inverted_pendulum_nonlin_simulator.make_step(u0)\n",
    "\n",
    "animate_inverted_pendulum_simulation(inverted_pendulum_mpc_controller.data)\n",
    ":::\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(2)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation.reshape(-1, 1)).ravel()\n",
    ":::\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "mpc_controller = MPCController(inverted_pendulum_mpc_controller)\n",
    "results = simulate_environment(inverted_pendulum_env, max_steps=200, controller=mpc_controller)\n",
    "show_video(results.frames, fps=1 / inverted_pendulum_env.dt)\n",
    ":::\n",
    "\n",
    ":::{code-cell} ipython3\n",
    "plt.close()\n",
    "T = np.arange(len(results.observations)) * inverted_pendulum_env.dt\n",
    "plot_inverted_pendulum_results(T=T, observations=results.observations, actions=results.actions, reference=np.inf);\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MPC Controller Design Challenges\n",
    "\n",
    "Some of the challenges that we are faced with when designing an MPC controller include:\n",
    "\n",
    "- Choosing the right hyper-parameters to ensure optimality as well as feasibility.\n",
    "- Ensuring recursive feasibility and achieving optimality despite a short prediction horizon.\n",
    "- Satisfying input and state constraints in the presence of uncertainty.\n",
    "- Ensuring computational tractability by properly reformulating constraints and costs and parameterizing control policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Robust MPC\n",
    "\n",
    "Robust Model Predictive Control (RMPC) is related to a variety of methods designed to guarantee control performance using optimization algorithms while considering systems with uncertainties. It is concerned with the control of system that are only approximately known. Usually, it is assumed that the system lies in a set of possible systems and this set can be quantitatively characterized\n",
    "\n",
    "- Robust MPC guarantees constraint satisfaction for all uncertain element realizations.\n",
    "- The model is split into a nominal part and additive uncertainty in a compact set. \n",
    "- The controller is designed to be robust against the uncertainty.\n",
    "- The MPC cost is typically optimized for the nominal system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Multi-Stage MPC\n",
    "\n",
    "The basic idea for the multi-stage approach is to consider various scenarios, where a scenario is defined by one possible realization of all uncertain parameters at every control instant within the horizon. The family of all considered discrete scenarios can be represented as a tree structure, called the scenario tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{figure} ./_static/images/40_multi_state_mpc.png\n",
    ":width: 60%\n",
    ":align: center\n",
    "Scenario tree representation of the uncertainty\n",
    "evolution for multi-stage MPC.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Each node in the tree denotes the possible state of the system at every prediction step.\n",
    "- The branches represent the different possible realizations of the uncertainty.\n",
    "- The initial state of the system forms the root node of the tree.\n",
    "- The root node branches into several nodes in the first stage depending on the number of vertex matrix pairs of the parametric uncertainty.\n",
    "- All the nodes in the first stage branch again in the second stage.\n",
    "- The sequence continues until the end of prediction horizon N to form the complete scenario tree.\n",
    "- A path from the root node to the leaf node represents a scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inverted Pendulum\n",
    "\n",
    "In a real system, we cannot usually determine the model parameters exactly and this represents an important source of uncertainty.\n",
    "\n",
    "In this example, we consider that the mass of the pole is not known precisely and is different from its nominal value but we know which possible values it may take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_pendulum_env = create_inverted_pendulum_environment(\n",
    "    max_steps=200, theta_initial=180, theta_threshold=np.inf\n",
    ")\n",
    "\n",
    "inverted_pendulum_nonlin_model = build_inverted_pendulum_nonlinear_model(\n",
    "    inverted_pendulum_env, with_uncertainty=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_p_values = inverted_pendulum_env.masspole * np.array([1.0, 1.30, 0.70])\n",
    "uncertainty_values = {\"m_p\": m_p_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoint = np.zeros((4, 1))\n",
    "setpoint[0] = 1.0\n",
    "distance_cost = casadi.bilin(\n",
    "    np.diag([1, 0, 100, 0]), inverted_pendulum_nonlin_model.x.cat - setpoint\n",
    ")\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "force_penalty = 1e-2\n",
    "display_array(\"Setpoint\", setpoint)\n",
    "print(f\"{stage_cost=}\")\n",
    "print(f\"{terminal_cost=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_limits = np.array([-np.inf, np.inf])\n",
    "u_limits = np.array([-inverted_pendulum_env.force_max, inverted_pendulum_env.force_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_pendulum_mpc_controller = build_mpc_controller(\n",
    "    model=inverted_pendulum_nonlin_model,\n",
    "    t_step=inverted_pendulum_env.dt,\n",
    "    n_horizon=100,\n",
    "    stage_cost=stage_cost,\n",
    "    terminal_cost=terminal_cost,\n",
    "    force_penalty=force_penalty,\n",
    "    x_limits=x_limits,\n",
    "    u_limits=u_limits,\n",
    "    uncertainty_values=uncertainty_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(4)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return self.mpc.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 200\n",
    "controller = MPCController(inverted_pendulum_mpc_controller)\n",
    "results = simulate_environment(\n",
    "    inverted_pendulum_env, max_steps=max_steps, controller=controller\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "show_video(results.frames, fps=1 / inverted_pendulum_env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_full_inverted_pendulum_simulation(inverted_pendulum_mpc_controller.data)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "scenes_data": {
   "active_scene": "Initialization",
   "init_scene": "Initialization",
   "scenes": [
    "Initialization"
   ]
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
